{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP 433\n",
    "## Groupe 2\n",
    "### DM 2\n",
    "\n",
    "COSTA, Caio; SILVA CLAUDINO, Ariel; ZUIN RUIZ, Luis Henrique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie Théorique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1. Montrer que le modèle est identifiable\n",
    "\n",
    "Si $\\mathbb{P}_\\theta = \\mathbb{P}_{\\theta'}$,\n",
    "\n",
    "alors pour tout $1 \\le i \\le n$, on a $\\mathrm{Ber}(\\varphi(\\theta^T \\mathbf{x}_i)) = \\mathrm{Ber}(\\varphi(\\theta'^T \\mathbf{x}_i))$,\n",
    "\n",
    "et donc pour tout $1 \\le i \\le n$, $\\varphi(\\theta^T \\mathbf{x}_i) = \\varphi(\\theta'^T \\mathbf{x}_i)$.\n",
    "\n",
    "Ainsi, vu que la fonction sigmoide $\\varphi$ est bijective, on a $\\theta^T \\mathbf{x}_i = \\theta'^T \\mathbf{x}_i$ pour tout $1 \\le i \\le n$.\n",
    "\n",
    "Donc, $X_n \\theta = X_n \\theta'$, et comme $X_n$ est de rang plein, on a $\\theta = \\theta'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. Monter que $F_n(\\theta)$ est définie positive\n",
    "\n",
    "Soit $w \\in \\mathbb{R}^p$. On veut montrer que $w^T F_n(\\theta) w \\ge 0$ et que $w^T F_n(\\theta) w = 0$ si et seulement si $w = 0$.\n",
    "\n",
    "$$\\begin{align*}\n",
    "w^T F_n(\\theta) w &= \\sum_{i=1}^n h(\\theta^T \\mathbf{x}_i) w^T \\mathbf{x}_i \\mathbf{x}_i^T w \\\\\n",
    "&= \\sum_{i=1}^n h(\\theta^T \\mathbf{x}_i) (w^T \\mathbf{x}_i)^2 \\\\\n",
    "&\\ge 0,\n",
    "\\end{align*}$$\n",
    "\n",
    "car $h \\colon \\mathbb{R} \\to [0, 1]$ est positive. De plus, $h$ ne s'annule pas sur $\\mathbb{R}$, donc $w^T F_n(\\theta) w = 0$ si et seulement si $w^T \\mathbf{x}_i = 0$ pour tout $1 \\le i \\le n$, c'est-à-dire si et seulement si $X_n^T w = 0$. Comme $X_n$ est de rang plein, on a $w = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3. Montrer que $h$ est 1-Lipschitzienne sur $\\mathbb{R}$\n",
    "\n",
    "On va estimer la dérivée de $h$.\n",
    "\n",
    "$$\\begin{align*}\n",
    "h(t) &= \\frac{e^t}{(1 + e^t)^2} \\\\\n",
    "\\implies h'(t) &= \\frac{e^t (1-e^t)}{(1 + e^t)^3}\n",
    "\\end{align*}$$\n",
    "\n",
    "Pour $t \\in \\mathbb{R}$, $e^t \\in (0, \\infty)$, donc il nous faut analyser le comportement de $f(y) = \\frac{y(1-y)}{(1+y)^3}$ sur $(0, \\infty)$.\n",
    "\n",
    "$$\\begin{align*}\n",
    "f'(y) &= \\frac{y^2 - 4y + 1}{(y+1)^4} = 0 \\iff y = 2 \\pm \\sqrt{3} \\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La valeur maximale de |f(y)| est 0.09622145382044442\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAHHCAYAAAB5gsZZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABj20lEQVR4nO3de1xUZf4H8M8MDDPchjsMKAiYCV4RTEK7qSikv11NszJdL7lam5RJl822srJdc1stK8sts5uaZltupWuSl0rFG2ilIt5FuSOX4SLDwJzfHzCjExdBZubMHD7v14vXxplzznzPAziffZ7nPEcmCIIAIiIiIrphcrELICIiInJ0DFREREREncRARURERNRJDFREREREncRARURERNRJDFREREREncRARURERNRJDFREREREncRARURERNRJDFREDuzgwYMYOnQo3N3dIZPJcOTIEdNrjz76KEaNGtXhc27duhUeHh4oLi62YKXWcaPXaEs32p4HDhyAi4sLLly4YKXKrE+v1yM0NBTvvvuu2KUQWR0DFZGD0uv1mDRpEkpLS/HGG2/gs88+Q48ePQAA586dw6pVq/Dcc891+LzJycm46aabsHjxYkuXbFGtXeN7772HSZMmISwsDDKZDDNmzBCnwCbtac9vv/0WcrkcBQUFpm1/+9vfMHnyZNPPFGgMWY8++iji4uKgUCggk8msWntnKRQKpKam4u9//ztqa2vb3Pd///sfFAoFXF1dsXv37lb3++mnn/DHP/4RoaGhUKlU0Gg0SE5Oxp49eyxdPlGHMFAROagzZ87gwoULeOqppzBnzhxMnToVPj4+AIDly5cjIiICw4cPv6FzP/zww/j3v/+NyspKS5ZsUa1d45IlS7Bjxw707dsXzs7OIlVn7nrtuXnzZsTFxUGj0QAAjhw5gh9++AGPPPKI2X5btmzBqlWrIJPJEBkZafW6LWHmzJkoKSnBunXrWt0nIyMD9913H3r37o2QkBCMGzcOJ06caHHfkydPQi6X45FHHsGKFSvw1FNPoaCgAHfccQe2bt1qrcsguj6BiBzSjz/+KAAQNm7caLa9rq5O8Pf3F55//vkbPndhYaHg5OQkfPjhh50t0yrausbz588LBoNBEARBcHd3F6ZPn27j6pq7XnuGhoYKCxcuNH3/+OOPC2FhYabrMCooKBBqamoEQRCEuXPnCp39J3znzp0CAOHcuXOdOs/1/N///Z9w++23t/jauXPnBI1GI/Tr108oKioSLly4IERGRgrh4eFCQUFBu85fXV0tBAUFCUlJSZYsm6hD2ENF5IBmzJiBO++8EwAwadIkyGQy3HXXXQCA3bt3o6SkBImJiab9q6qq4O7ujnnz5jU716VLl+Dk5GQ2JBUYGIgBAwbgv//9r3Uv5Bo7d+6ETCbD119/3ey1devWQSaTIT09HUDL12jUo0cPqw+FWbI9f/vtN1y8eBFjx441bdu0aRNGjBjR7DqCgoLg6upqwSu5MdOnT4e/vz/0en2z10aPHo3evXubbRs1ahR2796N0tJSs+2lpaW4++67ERAQgB07diAgIABhYWHYtWsX5HI5xo4di+rq6uvW4+bmhoCAAJSXl3fquog6g4GKyAE9/PDDprlDjz/+OD777DP87W9/AwDs3bsXMpkMgwYNMu3v4eGBe+65Bxs2bEBDQ4PZuT7//HMIgoApU6aYbY+Li8PevXuvW4tOp0NJSUm7vtpy1113ITQ0FGvXrm322tq1a9GzZ08kJCS0eo22ZMn23LJlCwIDAzF48GAAQG5uLnJychAbG2u9C+ikP/3pT7h8+TK+//57s+0FBQXYsWMHpk6darY9Li4OgiCYXb9Op8O4cePg4uJiClNGoaGh2LVrF8rLyzFp0iTU19c3q0Gr1aKkpAQnTpzAc889h6NHj2LkyJEWvlKi9mOgInJACQkJprvbbr/9dkydOtX0/YkTJ+Dr6wu1Wm12zLRp01BYWIi0tDSz7WvWrMEdd9yBsLAws+2RkZEoKSlBUVFRm7V8/vnnCAgIaNdXW2QyGaZOnYrvvvsOFRUVpu3FxcXYtm2b2Yd0a9doS5Zqz82bN+Puu+829UYZ5w5FRERYsfrOGTFiBLp37441a9aYbf/8889hMBiaBSrjfK/jx4+btimVSvz888/45Zdf4O/v3+w9QkNDcfr0aWzZsqXFuXD33XcfAgICEB0djaVLl+Lhhx/GCy+8YInLI7oh9jFjk4gs5vLly6bJ6ddKTExESEgI1q5di+TkZADA0aNH8euvv+KDDz5otr/xHCUlJQgMDGz1/ZKSkpqFihs1bdo0LF68GF9++SVmzZoFANiwYQPq6+vNPqRbu0ZbskR7lpeXIz09HY899phpv8uXL5vtb0kVFRVmw3TG4FpWVgYPDw/TdpVKZfb978nlckyZMgVvvfUWKisr4enpCaCxJ3Ho0KHNwuC1124pr732Gp588klcvHgRn3zyCerq6lrsySKyFQYqIgkSBKHZNuOH4HvvvYeamhq4ublh7dq1UKlUmDRpUqvnuN58pODgYAQHB1uk7qioKNxyyy1Yu3atKVCtXbsWt956K2666aYW67OUhoaGZmtF+fr6wsXFpcX9LdGexiGz0aNHt7q/JY0bNw4//vhjs+2/H16cPn06Pv744zbPNW3aNCxZsgRff/01pk2bhuzsbGRkZGDlypXN9m3v71JHxMTEmP576tSpiI2NxYwZM/Dll19a7D2IOoKBikhi/Pz8UFZW1uJr06ZNw+uvv45NmzZh8uTJWLduHf7v//4PXl5ezfY1nqOl4ZhrXblyxWyIri3GZQHaMm3aNMybNw+XLl2CTqfDvn378M4775jt09Y13qiLFy8261nZuXOnabJ/a7V2pj23bNmCYcOGme3v5+dntr8lLV261Oy8v/zyC5566imsWbMGQUFBpu0hISHXPVefPn0QFxeHNWvWYNq0aVizZg1cXFxw3333Ndu3vb9LN8rFxQV//OMf8dprr+HKlSt2MXGfuh4GKiKJiYqKwtq1a1FRUdHsg71fv34YNGgQ1q5di+7duyMnJwdvv/12i+c5d+4c/P39rzv3acOGDZg5c2a7amtPr8sDDzyA1NRUfP7557hy5QoUCgXuv/9+s33ausYbpdFomg1dDhw4sM1jOtOegiBg69ateOqpp8z2i4qKMu1vaXFxcWbfG+cmDRs2DOHh4R0+37Rp05Camor8/HysW7cOY8eObXGo0ngt0dHRHS+6na5cuQJBEFBZWclARaJgoCKSmISEBAiCgIyMDIwYMaLZ63/605/wzDPPQKlUws/PD3fffXeL58nIyDDdVdcWS86hAhp7Me6++26sWbMGtbW1SE5Obtazcb1rvBEqlarFZRiu50bb8+DBgygqKjJbLgEAunXrhtDQUBw6dKjDtdja5MmT8eSTT2LevHk4e/YsXn/99Rb3y8jIgEwma9fv0/UUFRU1m9NXXl6O//znPwgNDW1zvh+RNTFQEUnMbbfdBj8/P/zwww8tho0HH3wQzzzzDL7++mv85S9/gUKhaLZPUVERfv31V8ydO/e672fJOVRG06ZNw7333gsAWLRoUbPX27rGb7/9Fr/88guAxsfz/Prrr3j11VcBAH/84x8xYMAAi9Z6o+25efNmhIeHo0+fPs32HzduHL7++msIgmA27+jChQv47LPPAMAUuIzX1qNHD/zpT3+y6LVdT0BAAJKTk7Fx40Z4e3s3C4dGaWlpGDZsmGk4szPuvvtudO/eHfHx8QgMDEROTg4++ugj5OXlYcOGDZ0+P9ENE2ExUSKyAOMq179fKV0QGlfavummm1o9dsyYMQIAYe/evS2+/t577wlubm6CVqu1WL0dodPpBB8fH8HLy0u4cuVKi/u0do3Tp08XALT49dFHH1ml3htpz8GDBwuPPvpoi/tnZmYKAISff/7ZbLvxZ97S15133tnhui2xUvoXX3whABDmzJnT4uvl5eWCi4uLsGrVqht+j2u98847wm233Sb4+/sLzs7OQkBAgPCHP/xB+OmnnyxyfqIbxUBFJEFnzpwRFAqF8MMPP7T4+vjx44WePXu2enxMTIzwxBNPWKu869Lr9UJAQIDw0EMPtbrP9a7RljrangUFBYJMJhM2b97c6jEjRowQpk6datE6rWHTpk0CgFYDzRtvvCEEBwebHplDJFUMVEQS9cgjjwiJiYnNtufl5QkKhUJ46aWXWjzuf//7n+Du7i4UFhZau8RWbdy4UQAg7Nq1q839WrtGW7qR9szOzhYWLlzYZsjYt2+foFAohPPnz1u8ZksaO3asEBkZ2ey5g4LQ+MzF0NBQYcWKFSJURmRbMkGwwmInRGR3zp07hz179mDVqlU4ePAgzpw5065lDGxp//79+PXXX7Fo0SL4+/sjMzNT7JJa5QjtaU3r16/Hr7/+isWLF2P58uV4/PHHxS6JSFSclE7URfz444+YOXMmwsLC8Mknn9jlh/97772HNWvWICYm5roLS4rNEdrTmiZPngwPDw/MmjULjz76qNjlEImOPVREREREncSHIxMRERF1EgMVERERUSdxDpUNGAwG5OXlwdPT06IPByUiIiLrEZoeZxQSEgK5vO0+KAYqG8jLy0NoaKjYZRAREdENuHjxIrp3797mPgxUNuDp6Qmg8QeiVqstem69Xo9t27Zh9OjRLT7y4vcuV+lw37/TUajVYXxMCF69p79F65GyjrY13Ti2te2wrW2HbW07lmprrVaL0NBQ0+d4WxiobMA4zKdWq60SqNzc3KBWq6/7S1PfYMCc9cdQrHOCXOmGvRevwMPDE3I5hyHboyNtTZ3DtrYdtrXtsK1tx9Jt3Z7pOpyU3oW89r8T2He2FO4uTnBzcUJJlQ5H8yrELouIiMjhMVB1Ef89kotVu88BAJbeF4Pbe/kDAHaeKBazLCIiIklgoOoCsvK1+Ot/fgUAPHpXTyT302B470AAwI7sIjFLIyIikgQGKomrbzDgL2syUKs34I6bA/Dk6N4AgOFRjYHq10vlKKnSiVkiERGRw2Ogkrjzl2tw/nINXBVOeOuBGDg1TUAPUqvQN0QNQQB2ZXPYj4iIqDMYqCSuuLKx9ynYWwVvNxez10Y09VLt5LAfERFRpzBQSVxRZS0AIMBD2ew147DfTyeLoW8w2LQuIiIiKWGgkjhjD1WAZ/NANbC7N3zdXVBZW4+MC2W2Lo2IiEgyGKgkrrhpwnmgp6rZa05yGe68OQAAsPMEh/2IiIhuFAOVxLXVQwVcHfbjPCoiIqIbx0AlcdcLVHf2CoCTXIaThVW4VFZjy9KIiIgkg4FK4oyBKrCVQOXlpkBcmA8ADvsRERHdKAYqibteDxUA3BXVOI9qBwMVERHRDWGgkjB9gwGXq+sAtB2ojOtR7T1zGbX6BpvURkREJCUMVBJ2uaoxTDnJZfD93aKe1+od5Alfdxfo6g04XVRlq/KIiIgkg4FKwozDff4eLpA3PXKmJTKZDL2DPAE0PkiZiIiIOoaBSsJMq6S3Mdxn1FvTGKiyCyqtWhMREZEUMVBJ2NU7/Jov6vl70cFNgaqQgYqIiKijGKgkzHSHXwvP8fu93ho1ACArn4GKiIiooxioJMz42Jn2DPndHOQBmQwoqdLhctNxRERE1D4MVBJWpG1/oHJzcUYPXzcAnEdFRETUUQxUEnb1wcjXD1TA1YnpWQxUREREHcJAJWHtWSX9WsZ5VNkFXDqBiIioIxioJEoQhA4tmwAA0U09VCfYQ0VERNQhDFQSVaWrR63eAKAjPVSNgepkYSUaDILVaiMiIpIaBiqJMg73eSid4ebi3K5jevi5Q6WQo1ZvQE5pjTXLIyIikhQGKonq6PwpoPGZfzc3PYLmBB9BQ0RE1G4MVBJVdAOBCoDpmX6cR0VERNR+DFQSdSM9VAAQFWy804+BioiIqL0YqCTKtEp6Ox47c60o051+HPIjIiJqLwYqiTKukh6o7uCQX1OgulBag5q6eovXRUREJEUMVBJ1oz1U/h5K+HsoIQjAqcIqa5RGREQkOQxUEnWjc6gADvsRERF1FAOVRBkDVaCnqsPH9uaK6URERB3icIFqxYoVCA8Ph0qlQnx8PA4cONDm/hs3bkRUVBRUKhX69++PLVu2mL0uk8la/Hr99ddN+4SHhzd7/bXXXrPK9VlCfYMBl6st0EOVz0BFRETUHg4VqDZs2IDU1FQsXLgQmZmZGDhwIJKSklBUVNTi/nv37sXkyZMxa9YsHD58GOPHj8f48eNx9OhR0z75+flmX6tXr4ZMJsPEiRPNzvXKK6+Y7ffYY49Z9Vo7o7S6DoIAyGWAr7tLh4+PMj4kubASgsBH0BAREV2PQwWqZcuWYfbs2Zg5cyb69OmDlStXws3NDatXr25x/+XLlyM5ORlPP/00oqOjsWjRIsTGxuKdd94x7aPRaMy+/vvf/2L48OGIjIw0O5enp6fZfu7u7la91s4wLurp56GEk1zW4eN7BXlALmsMZsbJ7URERNS69j3kzQ7U1dUhIyMDCxYsMG2Ty+VITExEenp6i8ekp6cjNTXVbFtSUhI2bdrU4v6FhYXYvHkzPvnkk2avvfbaa1i0aBHCwsLw4IMPYv78+XB2brn5dDoddLqrQUSrbZzcrdfrodfr27zOjjKe79rz5pdXAwACPFxu6P2cAIT7ueFsSQ2OXirD7Tf5W6RWR9dSW5N1sK1th21tO2xr27FUW3fkeIcJVCUlJWhoaEBQUJDZ9qCgIJw4caLFYwoKClrcv6CgoMX9P/nkE3h6emLChAlm2x9//HHExsbC19cXe/fuxYIFC5Cfn49ly5a1eJ7Fixfj5ZdfbrZ927ZtcHNza/UaOyMtLc303/uKZACcIFypaDZnrL3UBjkAOf676yAqT3LY71rXtjVZF9vadtjWtsO2tp3OtnVNTU2793WYQGULq1evxpQpU6BSmd8Zd20v14ABA+Di4oKHH34YixcvhlLZfNL3ggULzI7RarUIDQ3F6NGjoVarLVqzXq9HWloaRo0aBYVCAQC48ONZ4Mxp9InsjjFj+t3Qec+4nsGRHWcg9w294XNITUttTdbBtrYdtrXtsK1tx1JtbRxhag+HCVT+/v5wcnJCYWGh2fbCwkJoNJoWj9FoNO3e/+eff0Z2djY2bNhw3Vri4+NRX1+P8+fPo3fv3s1eVyqVLQYthUJhtT+ia899ubqxi1Lj5XrD79db4wUAOFdSwz/837Hmz5HMsa1th21tO2xr2+lsW3fkWIeZlO7i4oK4uDhs377dtM1gMGD79u1ISEho8ZiEhASz/YHG7r+W9v/www8RFxeHgQMHXreWI0eOQC6XIzAwsINXYRs3ukr6tXoGNk66P1tcxTv9iIiIrsNheqiAxqG36dOnY/DgwRgyZAjefPNNVFdXY+bMmQCAadOmoVu3bli8eDEAYN68ebjzzjuxdOlSjB07FuvXr8ehQ4fw/vvvm51Xq9Vi48aNWLp0abP3TE9Px/79+zF8+HB4enoiPT0d8+fPx9SpU+Hj42P9i74BV1dJ7/iinkbhfu6QyQBtbT0uV9fBvxPhjIiISOocKlDdf//9KC4uxosvvoiCggLExMRg69atponnOTk5kMuvdroNHToU69atw/PPP4/nnnsOvXr1wqZNm9Cvn/mcoPXr10MQBEyePLnZeyqVSqxfvx4vvfQSdDodIiIiMH/+/GZ3D9oT0yrpHXww8rVUCid083bFpbIrOFtczUBFRETUBocKVACQkpKClJSUFl/btWtXs22TJk3CpEmT2jznnDlzMGfOnBZfi42Nxb59+zpcp5iM61B1ZsgPACIDPJoCVRWGRPhaojQiIiJJcpg5VNQ+1bp61NQ1ALixx85cK9K/cR7VmeKqTtdFREQkZQxUEmMc7nN3cYK7snMdkD0DPQAAZ4urO10XERGRlDFQSYxpuK+TvVMA0LOph+psCQMVERFRWxioJKbYgoEqMqCxhyqntAZ19YZOn4+IiEiqGKgkpriyFgAQ2IklE4yC1Eq4uzihwSAgp7T9y+8TERF1NQxUEmNa1NMCPVQymczUS8WJ6URERK1joJKYIq3lAhUARAYYV0znPCoiIqLWMFBJTMWVxuf4ebla5jlRkf7GO/3YQ0VERNQaBiqJqW2aPK5SOFnkfKYeKt7pR0RE1CoGKomp1Tcu6qlSWOZHe3XIjz1URERErWGgkhidMVA5W6iHqmnIr6xGj9LqOouck4iISGoYqCSmVm/ZIT9Xl8aHJAPspSIiImoNA5XE6OotO+QH8E4/IiKi62GgkhhL91AB1zwkuYQ9VERERC1hoJKYWqv0UPEhyURERG1hoJIY411+SgtNSgeAnlwtnYiIqE0MVBIiCIJ1hvya5lDlXK6BvoEPSSYiIvo9BioJ0dVfDTuWHPLTqFVwVTih3iDgIh+STERE1AwDlYTo9NcGKsv1UMnlMkT4804/IiKi1jBQSYhxQrqTXAaFk2V/tFcfQcN5VERERL/HQCUhpsfOOFv+x2qamF7EHioiIqLfY6CSEGtMSDdiDxUREVHrGKgk5OqDkS0fqHpyLSoiIqJWMVBJiGkNKgve4WdknJR+uboOFTV6i5+fiIjIkTFQSUht07IJKgsu6mnkrnSGRq0CwEfQEBER/R4DlYRcHfKzzo/VOI/qHIf9iIiIzDBQSYg151ABV4f9zpUwUBEREV2LgUpCdFa8yw+45iHJHPIjIiIyw0AlIcaFPa025MfV0omIiFrEQCUhVxf2tO6Q3/nL1TAYBKu8BxERkSNioJIQ48KeSisN+XX3cYXCSYZavQH52lqrvAcREZEjYqCSEGvf5efsJEeYrxsA3ulHRER0LQYqCbHmo2eMIvwbJ6af48R0IiIiEwYqCTFNSrfSHCrg6lpUZ9hDRUREZMJAJSHWHvIDrt7px7WoiIiIrmKgkhBrr0MFcHFPIiKiljBQSYgteqgimob8LpXVQNc0xEhERNTVOVygWrFiBcLDw6FSqRAfH48DBw60uf/GjRsRFRUFlUqF/v37Y8uWLWavz5gxAzKZzOwrOTnZbJ/S0lJMmTIFarUa3t7emDVrFqqq7G9S9tWFPa3XQxXgoYSn0hkGAci5XGO19yEiInIkDhWoNmzYgNTUVCxcuBCZmZkYOHAgkpKSUFRU1OL+e/fuxeTJkzFr1iwcPnwY48ePx/jx43H06FGz/ZKTk5Gfn2/6+vzzz81enzJlCo4dO4a0tDR89913+OmnnzBnzhyrXeeNMq1DZcVJ6TKZzNRLdZbDfkRERAAcLFAtW7YMs2fPxsyZM9GnTx+sXLkSbm5uWL16dYv7L1++HMnJyXj66acRHR2NRYsWITY2Fu+8847ZfkqlEhqNxvTl4+Njei0rKwtbt27FqlWrEB8fj9tuuw1vv/021q9fj7y8PKteb0fZYsgP4DwqIiKi33MWu4D2qqurQ0ZGBhYsWGDaJpfLkZiYiPT09BaPSU9PR2pqqtm2pKQkbNq0yWzbrl27EBgYCB8fH4wYMQKvvvoq/Pz8TOfw9vbG4MGDTfsnJiZCLpdj//79uOeee5q9r06ng06nM32v1WoBAHq9Hnq9vmMXfh3G8+n1elypawxUzjLB4u9zrR4+rgCA04WVVn0fe3NtW5N1sa1th21tO2xr27FUW3fkeIcJVCUlJWhoaEBQUJDZ9qCgIJw4caLFYwoKClrcv6CgwPR9cnIyJkyYgIiICJw5cwbPPfcc7r77bqSnp8PJyQkFBQUIDAw0O4ezszN8fX3NznOtxYsX4+WXX262fdu2bXBzc2vX9XZUWloayiudAMiQeWAfLmdZ5W0AABUlMgBOyDx1CVu2XLDeG9mptLQ0sUvoMtjWtsO2th22te10tq1rato/V9hhApW1PPDAA6b/7t+/PwYMGICePXti165dGDly5A2dc8GCBWY9Y1qtFqGhoRg9ejTUanWna76WXq9HWloaRo0ahVd+3QPo6jDiztvRW+Np0fe5Vo88LT45tQ8VBiXGjLnLau9jb65ta4VCIXY5ksa2th22te2wrW3HUm1tHGFqD4cJVP7+/nByckJhYaHZ9sLCQmg0mhaP0Wg0HdofACIjI+Hv74/Tp09j5MiR0Gg0zSa919fXo7S0tNXzKJVKKJXKZtsVCoXV/ogUCgV09Y2T0j1clVb9Y71J4wUAuFxdh5p6wMu1a/3DYM2fI5ljW9sO29p22Na209m27sixDjMp3cXFBXFxcdi+fbtpm8FgwPbt25GQkNDiMQkJCWb7A43df63tDwCXLl3C5cuXERwcbDpHeXk5MjIyTPvs2LEDBoMB8fHxnbkki7s6Kd16d/kBgIfSGUHqxsDIielEREQOFKgAIDU1FR988AE++eQTZGVl4S9/+Quqq6sxc+ZMAMC0adPMJq3PmzcPW7duxdKlS3HixAm89NJLOHToEFJSUgAAVVVVePrpp7Fv3z6cP38e27dvx7hx43DTTTchKSkJABAdHY3k5GTMnj0bBw4cwJ49e5CSkoIHHngAISEhtm+EVtQ3GFBvEABY/y4/4No7/exvPS4iIiJbc5ghPwC4//77UVxcjBdffBEFBQWIiYnB1q1bTRPPc3JyIJdfDRNDhw7FunXr8Pzzz+O5555Dr169sGnTJvTr1w8A4OTkhF9//RWffPIJysvLERISgtGjR2PRokVmQ3Zr165FSkoKRo4cCblcjokTJ+Ktt96y7cVfR23TcB9g/R4qAIjw98C+s6U4y4ckExEROVagAoCUlBRTD9Pv7dq1q9m2SZMmYdKkSS3u7+rqiu+///667+nr64t169Z1qE5b0+mvPgbGxcn6PVQ9ubgnERGRiUMN+VHrjD1ULs5yyOUyq7+faciPPVREREQMVFJhfOyMytk2P9JrV0s3NM3dIiIi6qoYqCTCVnf4GYX6usFZLsMVfQMKK2tt8p5ERET2ioFKIoxrUNkqUCmc5AjzbVz1ncN+RETU1TFQSYStHox8LeOwHyemExFRV8dAJRG1Nu6hAq4JVOyhIiKiLo6BSiKMyyaonG0XqCIDPAAAZ7m4JxERdXEMVBJhvMtPacMhv8gA9lAREREBDFSSUVtv27v8gKuB6lJZjWkOFxERUVfEQCURpnWobBioAjyU8FQ5wyAAFy7X2Ox9iYiI7A0DlURcnUNlux+pTCZDz6Z5VGeKOY+KiIi6LgYqiRDjLj/g2nlUDFRERNR1MVBJhBjrUAG4poeKE9OJiKjrYqCSCFuvlG7Us6mHikN+RETUlTFQSYQYk9KBqz1UZ4urIQh8SDIREXVNDFQSYRzyU9pwUjoAhPm5wUkuQ5WuHkWVOpu+NxERkb1goJIIsYb8lM5OCPVxBQCcKeKwHxERdU0MVBJxdVK6bQMVcM3EdD4kmYiIuigGKom42kNl+x9pz8CmQMUeKiIi6qIYqCTC9OgZGz4c2SjSn3f6ERFR18ZAJRE6ke7yA672UPEhyURE1FUxUEnE1WUTRBjya5pDlVt+BVfq+JBkIiLqehioJMI05CdCD5Wvuwu83RQAgLMlHPYjIqKuh4FKInQi9lAB5gt8EhERdTUMVBJh7KFSijApHeAjaIiIqGtjoJIAQRDv0TNGkXxIMhERdWEMVBJQf80j9MQf8mMPFRERdT0MVBLQ1DkFQLweKuOQ39niahgMfEgyERF1LQxUEmAMVE5yGRRO4vxIQ33d4CyX4Yq+AfnaWlFqICIiEgsDlQQYA5XKWbwfp8JJjh5+bgA47EdERF0PA5UE1BkDlUjDfUamiel8ph8REXUxDFQSoLeTQNWTd/oREVEXxUAlAcZApRTpDj8j08R0rpZORERdDAOVBOgNMgCASqRFPY2uDvmxh4qIiLoWBioJuDrkZx89VAXaWlTp6kWthYiIyJYYqCTAXuZQebu5wN/DBQBwjvOoiIioC2GgkgB7CVTA1WG/U0WVIldCRERkOw4XqFasWIHw8HCoVCrEx8fjwIEDbe6/ceNGREVFQaVSoX///tiyZYvpNb1ej7/+9a/o378/3N3dERISgmnTpiEvL8/sHOHh4ZDJZGZfr732mlWu70bYy5AfAPQKbAxUp7l0AhERdSHifwJ3wIYNG5CamoqFCxciMzMTAwcORFJSEoqKilrcf+/evZg8eTJmzZqFw4cPY/z48Rg/fjyOHj0KAKipqUFmZiZeeOEFZGZm4quvvkJ2djb++Mc/NjvXK6+8gvz8fNPXY489ZtVr7YirC3uK30NlDFQnCxmoiIio63CoQLVs2TLMnj0bM2fORJ8+fbBy5Uq4ublh9erVLe6/fPlyJCcn4+mnn0Z0dDQWLVqE2NhYvPPOOwAALy8vpKWl4b777kPv3r1x66234p133kFGRgZycnLMzuXp6QmNRmP6cnd3t/r1ttfVZRPED1Q3B3kCAE5zyI+IiLoQZ7ELaK+6ujpkZGRgwYIFpm1yuRyJiYlIT09v8Zj09HSkpqaabUtKSsKmTZtafZ+KigrIZDJ4e3ubbX/ttdewaNEihIWF4cEHH8T8+fPh7Nxy8+l0Ouh0OtP3Wq0WQOMQo16vb+syO0yv16OuadkEFydY/PwdFe6rAgBcKK1BZU2tXczrshRj24rdxl0B29p22Na2w7a2HUu1dUeOd5hAVVJSgoaGBgQFBZltDwoKwokTJ1o8pqCgoMX9CwoKWty/trYWf/3rXzF58mSo1WrT9scffxyxsbHw9fXF3r17sWDBAuTn52PZsmUtnmfx4sV4+eWXm23ftm0b3Nzc2rzOG6E3NHY05l44jy1bzlr8/B0hCICbsxNq6mX4dNP36G4/HXkWk5aWJnYJXQbb2nbY1rbDtradzrZ1TU1Nu/d1mEBlbXq9Hvfddx8EQcB7771n9tq1vVwDBgyAi4sLHn74YSxevBhKpbLZuRYsWGB2jFarRWhoKEaPHm0W1CxV94Z/bwcA9InqhTHDe1r0/DdiTf4BHLpQDs3NgzBmYLDY5ViMXq9HWloaRo0aBYVCIXY5ksa2th22te2wrW3HUm1tHGFqD4cJVP7+/nByckJhYaHZ9sLCQmg0mhaP0Wg07drfGKYuXLiAHTt2XDf0xMfHo76+HufPn0fv3r2bva5UKlsMWgqFwip/RMY5VO5K65y/o27WqHHoQjnOXq6xi3oszVo/R2qObW07bGvbYVvbTmfbuiPHOsykdBcXF8TFxWH79u2mbQaDAdu3b0dCQkKLxyQkJJjtDzR2/127vzFMnTp1Cj/88AP8/PyuW8uRI0cgl8sRGBh4g1djWfa0DhVw9U6/U7zTj4iIugiH6aECGofepk+fjsGDB2PIkCF48803UV1djZkzZwIApk2bhm7dumHx4sUAgHnz5uHOO+/E0qVLMXbsWKxfvx6HDh3C+++/D6AxTN17773IzMzEd999h4aGBtP8Kl9fX7i4uCA9PR379+/H8OHD4enpifT0dMyfPx9Tp06Fj4+POA3xO6a7/JztIx8b7/Q7xbWoiIioi3CoQHX//fejuLgYL774IgoKChATE4OtW7eaJp7n5ORALr8aKoYOHYp169bh+eefx3PPPYdevXph06ZN6NevHwAgNzcX33zzDQAgJibG7L127tyJu+66C0qlEuvXr8dLL70EnU6HiIgIzJ8/v9ndg2Ky1x6qC5erUatvsJu6iIiIrMWhAhUApKSkICUlpcXXdu3a1WzbpEmTMGnSpBb3Dw8PhyAIbb5fbGws9u3b1+E6bUnftGyCPayUDgABnkqoVc7Q1tbjXEk1ooMtOxGfiIjI3tjHJzB1ij0t7AkAMpnMNOx3spALfBIRkfQxUEmAPT16xqhXEJ/pR0REXQcDlQTY08ORjXoFsoeKiIi6Dvv5BKYbVmdnk9KBqz1UvNOPiIi6AgYqCbC3u/yAq0snXLhcA119g8jVEBERWRcDlQTY45BfoKcSnipnNBgEnCupFrscIiIiq7KfT2C6IfUNBhiEpmUT7GhSukwm44rpRETUZTBQObjaeoPpv+1pyA+4ZsV0TkwnIiKJY6BycDr91flJ9vLoGaObAjkxnYiIugb7+gSmDjP2ULk4yyGXy0Suxhyf6UdERF0FA5WDq22aka6ys94p4OrSCedLqlF3zdAkERGR1NjfpzB1SG3TkJ+9zZ8CAI1aBU+lM+oNAs5f5p1+REQkXQxUDk7X1PNjb/OngMY7/W5q6qXiiulERCRl9vcpTB1ytYfKPn+UNwca7/TjPCoiIpIu+/wUpnYzTkq3xyE/gA9JJiKiroGBysEZl02wxyE/4OrSCdkc8iMiIgmzz09hajfTXX522kMVpVEDAM6VVJuGJ4mIiKSGgcrB1TY9eNgel00AgCC1Et5uCjQYBA77ERGRZNnnpzC1m7GHSmmnPVQymQzRTb1UWflakashIiKyDgYqB6ez87v8ACAquPFOvxMFnEdFRETSZL+fwtQuprv8nO2zhwqAqYfqRAF7qIiISJoYqBycva9DBQDRwcYhv0oIgiByNURERJZnv5/C1C5XV0q33x6qXkEekMuA0uo6FFfqxC6HiIjI4hioHNzVZRPs90epUjghwt8dAJDFeVRERCRB9vspTO2iq7ffhyNfK6pp2O8E7/QjIiIJYqBycKZlE+x0HSqjPsFcOoGIiKTLvj+F6bqu9lDZ948ySsOlE4iISLrs+1OYrss0h8qOJ6UDV4f8ThdVoa5pIj0REZFUMFA5OOOjZ5R23kMV4qWCWuWMej6ChoiIJMi+P4XpunR2/nBkI5lMdnViOhf4JCIiiWGgcnBXh/zs/0cZzXlUREQkUfb/KUxtqnWQZROAq/OoeKcfERFJjXNHds7KysL69evx888/48KFC6ipqUFAQAAGDRqEpKQkTJw4EUql0lq1Ugt0DrJsAmD+CBoiIiIpadencGZmJhITEzFo0CDs3r0b8fHxeOKJJ7Bo0SJMnToVgiDgb3/7G0JCQrBkyRLodHy8iK04Ug/VzUEekMmAkiodH0FDRESS0q4eqokTJ+Lpp5/Gl19+CW9v71b3S09Px/Lly7F06VI899xzlqqRWiEIgkM8esbIzcUZ4X7uOFdSjeyCSgR4sjeTiIikoV2B6uTJk1AoFNfdLyEhAQkJCdDr9Z0ujK5Pd816Tvb8cORrRWk8ca6kGln5WtzWy1/scoiIiCyiXd0a14aps2fPdmh/sh7j/CnAMXqogGvmUXHpBCIikpAOfwrfdNNNGD58ONasWYPa2lpr1NSmFStWIDw8HCqVCvHx8Thw4ECb+2/cuBFRUVFQqVTo378/tmzZYva6IAh48cUXERwcDFdXVyQmJuLUqVNm+5SWlmLKlClQq9Xw9vbGrFmzUFUl/uKUxvlTcghQODlGoDI9goYT04mISEI6/CmcmZmJAQMGIDU1FRqNBg8//PB1Q42lbNiwAampqVi4cCEyMzMxcOBAJCUloaioqMX99+7di8mTJ2PWrFk4fPgwxo8fj/Hjx+Po0aOmff75z3/irbfewsqVK7F//364u7sjKSnJLCxOmTIFx44dQ1paGr777jv89NNPmDNnjtWv93pq9Y2BykE6pwBc7aE6XVQFfQMfQUNERNLQ4Y/imJgYLF++HHl5eVi9ejXy8/Nx2223oV+/fli2bBmKi4utUScAYNmyZZg9ezZmzpyJPn36YOXKlXBzc8Pq1atb3H/58uVITk7G008/jejoaCxatAixsbF45513ADT2Tr355pt4/vnnMW7cOAwYMACffvop8vLysGnTJgCNS0Vs3boVq1atQnx8PG677Ta8/fbbWL9+PfLy8qx2re1hnJDuSIGqu48rPJTOqGsw4GxxtdjlEBERWUSH1qEyO9DZGRMmTMDYsWPx7rvvYsGCBXjqqafw3HPP4b777sOSJUsQHBxssULr6uqQkZGBBQsWmLbJ5XIkJiYiPT29xWPS09ORmppqti0pKckUls6dO4eCggIkJiaaXvfy8kJ8fDzS09PxwAMPID09Hd7e3hg8eLBpn8TERMjlcuzfvx/33HNPs/fV6XRmS0dotY3zhfR6vUUn7FddaXwPhRwOdSNA7yAPZOSU47dLZYj0U4ldTrsZ29iR2tpRsa1th21tO2xr27FUW3fk+BsOVIcOHcLq1auxfv16uLu746mnnsKsWbNw6dIlvPzyyxg3bpxFhwJLSkrQ0NCAoKAgs+1BQUE4ceJEi8cUFBS0uH9BQYHpdeO2tvYJDAw0e93Z2Rm+vr6mfX5v8eLFePnll5tt37ZtG9zc3Fq7xA47Vwm4yJ2gdALS0tIsdl5rc9PJAcixec8vUOQeFrucDnOktnZ0bGvbYVvbDtvadjrb1jU1Ne3et8OBatmyZfjoo4+QnZ2NMWPG4NNPP8WYMWMglzeOO0VERODjjz9GeHh4R08tGQsWLDDrGdNqtQgNDcXo0aOhVqst+l5z9HqkpaVh1KhRDnN3ZU1mLn7++hiqlX4YM+YWsctpN70DtrWjYlvbDtvadtjWtmOptjaOMLVHhwPVe++9h4ceeggzZsxodUgvMDAQH374YUdP3SZ/f384OTmhsLDQbHthYSE0Gk2Lx2g0mjb3N/5vYWGh2bUUFhYiJibGtM/vJ73X19ejtLS01fdVKpUtPoJHoVBY7Y/Imue2tJgwXwDA8fxKODk5Qy6XiVxRxzhSWzs6trXtsK1th21tO51t644c2+HpzKdOncKCBQvanB/l4uKC6dOnd/TUbXJxcUFcXBy2b99u2mYwGLB9+3YkJCS0eExCQoLZ/kBj959x/4iICGg0GrN9tFot9u/fb9onISEB5eXlyMjIMO2zY8cOGAwGxMfHW+z6upJegR5QOstRpavH+cucmE5ERI6vXYEqJyenQyfNzc29oWKuJzU1FR988AE++eQTZGVl4S9/+Quqq6sxc+ZMAMC0adPMJq3PmzcPW7duxdKlS3HixAm89NJLOHToEFJSUgAAMpkMTzzxBF599VV88803+O233zBt2jSEhIRg/PjxAIDo6GgkJydj9uzZOHDgAPbs2YOUlBQ88MADCAkJscp1Sp2zk9y0fMJvuRUiV0NERNR57QpUt9xyCx5++GEcPHiw1X0qKirwwQcfoF+/fvjPf/5jsQKvdf/99+Nf//oXXnzxRcTExODIkSPYunWraVJ5Tk4O8vPzTfsPHToU69atw/vvv4+BAwfiyy+/xKZNm9CvXz/TPs888wwee+wxzJkzB7fccguqqqqwdetWqFRX7z5bu3YtoqKiMHLkSIwZMwa33XYb3n//fatcY1fRv5sXAOAoAxUREUlAu+ZQZWVl4dVXX8WoUaOgUqkQFxeHkJAQqFQqlJWV4fjx4zh27BhiY2Pxz3/+E2PGjLFawSkpKaYept/btWtXs22TJk3CpEmTWj2fTCbDK6+8gldeeaXVfXx9fbFu3boO10qtMwYq9lAREZEUtKuH6tKlS3j99deRn5+PFStWoFevXigpKTE9omXKlCnIyMhAenq6VcMUSUe/pkB1LFcLg0EQuRoiIqLOaVcP1aBBg1BQUICAgAA8/fTTOHjwIPz8/KxdG0lYr6DGiemVunpcKK1BhL+72CURERHdsHb1UHl7e+Ps2bMAgPPnz8Ng4DPYqHMUnJhOREQS0q4eqokTJ+LOO+9EcHAwZDIZBg8eDCcnpxb3NQYvouvp380LRy6W47dL5fjjQN4xSUREjqtdger999/HhAkTcPr0aTz++OOYPXs2PD09rV0bSRwnphMRkVS0e6X05ORkAEBGRgbmzZvHQEWd9vuJ6Y62YjoREZFRh1dK/+ijjximyCJ6BXnA5ZqJ6URERI6qw4GKyFI4MZ2IiKSCgYpE1b9bY6DiiulEROTIGKhIVKaJ6ZcYqIiIyHExUJGo+nfzBgAczauAIHDFdCIickwMVCQq08T02npcuMyJ6URE5JgYqEhU105M/5XzqIiIyEExUJHoODGdiIgcHQMViY4T04mIyNExUJHojCumH82rgMHAielEROR4GKhIdDcHeUKlaJyYfqa4SuxyiIiIOoyBikSncJJjQHdvAEBmTpm4xRAREd0ABiqyC7FhPgCAzAvl4hZCRER0AxioyC7EhnkDAA5fZA8VERE5HgYqsguxPRp7qE4VVUFbqxe5GiIioo5hoCK74O+hRJivGwQBOJJTLnY5REREHcJARXbDOOzHielERORoGKjIbhiH/TLZQ0VERA6GgYrshvFOv8M5ZVzgk4iIHAoDFdmNKI0nXBVOXOCTiIgcDgMV2Q1nJzkGdG98DA3nURERkSNhoCK7YppHxQU+iYjIgTBQkV0xrZjOHioiInIgDFRkVwY1LZ1wqqgKFVe4wCcRETkGBiqyK8YFPgHgyMVycYshIiJqJwYqsjum5/px2I+IiBwEAxXZHS7wSUREjoaBiuwOF/gkIiJHw0BFdocLfBIRkaNhoCK7wwU+iYjI0TBQkV2Ka5pHdfA8AxUREdk/hwlUpaWlmDJlCtRqNby9vTFr1ixUVbU9HFRbW4u5c+fCz88PHh4emDhxIgoLC02v//LLL5g8eTJCQ0Ph6uqK6OhoLF++3Owcu3btgkwma/ZVUFBgleukRvGRfgCAfWcvi1wJERHR9TmLXUB7TZkyBfn5+UhLS4Ner8fMmTMxZ84crFu3rtVj5s+fj82bN2Pjxo3w8vJCSkoKJkyYgD179gAAMjIyEBgYiDVr1iA0NBR79+7FnDlz4OTkhJSUFLNzZWdnQ61Wm74PDAy0zoUSAGBwDx84yWW4VHYFF0trENq0NhUREZE9cohAlZWVha1bt+LgwYMYPHgwAODtt9/GmDFj8K9//QshISHNjqmoqMCHH36IdevWYcSIEQCAjz76CNHR0di3bx9uvfVWPPTQQ2bHREZGIj09HV999VWzQBUYGAhvb2/rXCA14650xoDuXjicU47950oZqIiIyK45RKBKT0+Ht7e3KUwBQGJiIuRyOfbv34977rmn2TEZGRnQ6/VITEw0bYuKikJYWBjS09Nx6623tvheFRUV8PX1bbY9JiYGOp0O/fr1w0svvYRhw4a1Wq9Op4NOpzN9r9VqAQB6vR56vWUfp2I8n6XPaw+G9PDB4ZxypJ8pxrgBQWKXI+m2tjdsa9thW9sO29p2LNXWHTneIQJVQUFBsyE2Z2dn+Pr6tjqXqaCgAC4uLs16lYKCglo9Zu/evdiwYQM2b95s2hYcHIyVK1di8ODB0Ol0WLVqFe666y7s378fsbGxLZ5n8eLFePnll5tt37ZtG9zcrNPTkpaWZpXziklWLgPghF3HcrFFmSN2OSZSbGt7xba2Hba17bCtbaezbV1TU9PufUUNVM8++yyWLFnS5j5ZWVk2qeXo0aMYN24cFi5ciNGjR5u29+7dG7179zZ9P3ToUJw5cwZvvPEGPvvssxbPtWDBAqSmppq+12q1CA0NxejRo83mYVmCXq9HWloaRo0aBYVCYdFzi+1OXT0++MdOXNYBA4cORzdvV1HrkXJb2xu2te2wrW2HbW07lmpr4whTe4gaqJ588knMmDGjzX0iIyOh0WhQVFRktr2+vh6lpaXQaDQtHqfRaFBXV4fy8nKzXqrCwsJmxxw/fhwjR47EnDlz8Pzzz1+37iFDhmD37t2tvq5UKqFUKpttVygUVvsjsua5xeKtUKB/Ny8cuViOjBwtwgMsG0ZvlBTb2l6xrW2HbW07bGvb6Wxbd+RYUQNVQEAAAgICrrtfQkICysvLkZGRgbi4OADAjh07YDAYEB8f3+IxcXFxUCgU2L59OyZOnAig8U69nJwcJCQkmPY7duwYRowYgenTp+Pvf/97u+o+cuQIgoOD27Uvdc6tkX44crEc+85exsS47mKXQ0RE1CKHmEMVHR2N5ORkzJ49GytXroRer0dKSgoeeOAB0x1+ubm5GDlyJD799FMMGTIEXl5emDVrFlJTU+Hr6wu1Wo3HHnsMCQkJpgnpR48exYgRI5CUlITU1FTT3ConJydT0HvzzTcRERGBvn37ora2FqtWrcKOHTuwbds2cRqji7k10hcrfzyD/edKxS6FiIioVQ4RqABg7dq1SElJwciRIyGXyzFx4kS89dZbptf1ej2ys7PNJpC98cYbpn11Oh2SkpLw7rvvml7/8ssvUVxcjDVr1mDNmjWm7T169MD58+cBAHV1dXjyySeRm5sLNzc3DBgwAD/88AOGDx9u/YsmDA73hZNchpzSGuSWXxF9HhUREVFLHCZQ+fr6trmIZ3h4OARBMNumUqmwYsUKrFixosVjXnrpJbz00kttvu8zzzyDZ555psP1kmV4KJ1N86j2n72MCbEc9iMiIvvjMI+eoa7rVj6GhoiI7BwDFdm9+MjGhVb3neU8KiIisk8MVGT3jM/1yymtQV75FbHLISIiaoaBiuyep0qBft28AAD7z3HYj4iI7A8DFTmEW43Dfmc47EdERPaHgYocgmliOnuoiIjIDjFQkUMwzqO6cLkGl8ra/7BKIiIiW2CgIofgqVJgUKg3AOCnkyXiFkNERPQ7DFTkMO68ufFxQD+dLBa5EiIiInMMVOQw7uzdGKj2nC6BvsEgcjVERERXMVCRw+gX4gVfdxdU6upxOKdc7HKIiIhMGKjIYcjlMtzeyx8A8OPJIpGrISIiuoqBihyKcR7Vj5xHRUREdoSBihzK7b0aA9XRXC2KK3UiV0NERNSIgYocSoCnEv26qQEAu0+zl4qIiOwDAxU5HNOwXzYDFRER2QcGKnI4dzQN+/10qgQGgyByNURERAxU5IBie/jAQ+mM0uo6HM2rELscIiIiBipyPAonOYbd1PiwZA77ERGRPWCgIod0582BAICfTjFQERGR+BioyCHdcXPjAp+ZOeWouKIXuRoiIurqGKjIIXX3cUPPAHc0GATsPV0idjlERNTFMVCRwzIO++3M5mNoiIhIXAxU5LBGRjcGqu1ZRWjg8glERCQiBipyWEMifOHlqsDl6jocOl8qdjlERNSFMVCRw1I4yU29VN8fKxS5GiIi6soYqMihJfXVAAC+P1YAQeCwHxERiYOBihzaHb0CoFLIkVt+BcfytGKXQ0REXRQDFTk0Vxcn08OStx0rELkaIiLqqhioyOFdHfbjPCoiIhIHAxU5vJFRQXCWy5BdWInzJdVil0NERF0QAxU5PC83BW6NbHxY8vcc9iMiIhEwUJEkJPUNAsBARURE4mCgIkkY3TSPKjOnHEXaWpGrISKiroaBiiQhSK3CoDBvAMC245ycTkREtsVARZJx7SKfREREtsRARZJhDFTpZy6jokYvcjVERNSVOEygKi0txZQpU6BWq+Ht7Y1Zs2ahqqqqzWNqa2sxd+5c+Pn5wcPDAxMnTkRhoflwkEwma/a1fv16s3127dqF2NhYKJVK3HTTTfj4448tfXlkARH+7ojSeKLeIGDrsXyxyyEioi7EYQLVlClTcOzYMaSlpeG7777DTz/9hDlz5rR5zPz58/Htt99i48aN+PHHH5GXl4cJEyY02++jjz5Cfn6+6Wv8+PGm186dO4exY8di+PDhOHLkCJ544gn8+c9/xvfff2/pSyQL+GNMCADg68O5IldCRERdibPYBbRHVlYWtm7dioMHD2Lw4MEAgLfffhtjxozBv/71L4SEhDQ7pqKiAh9++CHWrVuHESNGAGgMTtHR0di3bx9uvfVW077e3t7QaDQtvvfKlSsRERGBpUuXAgCio6Oxe/duvPHGG0hKSrL0pVInjYvphn9uzcb+c6XIK7+CEG9XsUsiIqIuwCECVXp6Ory9vU1hCgASExMhl8uxf/9+3HPPPc2OycjIgF6vR2JiomlbVFQUwsLCkJ6ebhao5s6diz//+c+IjIzEI488gpkzZ0Imk5ne+9pzAEBSUhKeeOKJVuvV6XTQ6XSm77Xaxof26vV66PWWndtjPJ+lz+uoAt2dMSTcBwfOl+HrzIuYc3uExc7NtrYdtrXtsK1th21tO5Zq644c7xCBqqCgAIGBgWbbnJ2d4evri4KClu/oKigogIuLC7y9vc22BwUFmR3zyiuvYMSIEXBzc8O2bdvw6KOPoqqqCo8//rjpPEFBQc3OodVqceXKFbi6Nu8BWbx4MV5++eVm27dt2wY3N7d2XXNHpaWlWeW8jihCLsMBOGHN7pPoXpll8fOzrW2HbW07bGvbYVvbTmfbuqampt37ihqonn32WSxZsqTNfbKyLP+BeK0XXnjB9N+DBg1CdXU1Xn/9dVOguhELFixAamqq6XutVovQ0FCMHj0aarW6U/X+nl6vR1paGkaNGgWFQmHRczuqYVf0+GrJLuTXAJGxtyNK42mR87KtbYdtbTtsa9thW9uOpdraOMLUHqIGqieffBIzZsxoc5/IyEhoNBoUFRWZba+vr0dpaWmrc580Gg3q6upQXl5u1ktVWFjY6jEAEB8fj0WLFkGn00GpVEKj0TS7M7CwsBBqtbrF3ikAUCqVUCqVzbYrFAqr/RFZ89yOxl+hwMioIGw9VoDvjhaif6ivRc/PtrYdtrXtsK1th21tO51t644cK2qgCggIQEBAwHX3S0hIQHl5OTIyMhAXFwcA2LFjBwwGA+Lj41s8Ji4uDgqFAtu3b8fEiRMBANnZ2cjJyUFCQkKr73XkyBH4+PiYAlFCQgK2bNlitk9aWlqb5yDxjR8Ugq3HCvDfw3n4a1IU5HKZ2CUREZGEOcSyCdHR0UhOTsbs2bNx4MAB7NmzBykpKXjggQdMd/jl5uYiKioKBw4cAAB4eXlh1qxZSE1Nxc6dO5GRkYGZM2ciISHBNCH922+/xapVq3D06FGcPn0a7733Hv7xj3/gscceM733I488grNnz+KZZ57BiRMn8O677+KLL77A/Pnzbd8Q1G539Q6EWuWMAm0t9p27LHY5REQkcQ4RqABg7dq1iIqKwsiRIzFmzBjcdttteP/9902v6/V6ZGdnm00ge+ONN/B///d/mDhxIu644w5oNBp89dVXptcVCgVWrFiBhIQExMTE4N///jeWLVuGhQsXmvaJiIjA5s2bkZaWhoEDB2Lp0qVYtWoVl0ywcyqFE8YOCAYAbOKaVEREZGUOcZcfAPj6+mLdunWtvh4eHg5BEMy2qVQqrFixAitWrGjxmOTkZCQnJ1/3ve+66y4cPny4YwWT6MbFdMPnBy7if78V4JVx/aBSOIldEhERSZTD9FARddSQcF+EeKlQqavHjhNF1z+AiIjoBjFQkWTJ5TKMG9QNAPBV5iWRqyEiIiljoCJJmxjbGKh2nChCfsUVkashIiKpYqAiSbsp0BPxEb4wCMD6AxfFLoeIiCSKgYokb8qtPQAA6w/moL7BIHI1REQkRQxUJHlJfYPg5+6CQq0O2zk5nYiIrICBiiRP6eyESYNDAQBr9+eIXA0REUkRAxV1CQ8OCQMA/HSyGDmX2//0cCIiovZgoKIuIczPDXfc3PjcyHUH2EtFRESWxUBFXcbU+MZeqo2HLkJX3yByNUREJCUMVNRljIgKhEatwuXqOnx/rFDscoiISEIYqKjLcHaS44EhTZPT910QuRoiIpISBirqUh64JQxOchn2nyvFqcJKscshIiKJYKCiLkXjpcKo6CAAwKqfz4lcDRERSQUDFXU5c+6MBAB8fTgXhdpakashIiIpYKCiLic2zAdDwn1R12DA6j3spSIios5joKIu6eGmXqp1+3KgrdWLXA0RETk6Birqkob3DkSvQA9U6urxOR9HQ0REncRARV2SXC7DnDsae6lW7znHhT6JiKhTGKioyxoX0w1BaiUKtTr893Ce2OUQEZEDY6CiLsvFWY5Zt0UAAP790xkYDILIFRERkaNioKIubfKQMHgqnXGmuBrbTxSJXQ4RETkoBirq0jxVCky5tQcA4N1dpyEI7KUiIqKOY6CiLu+hYeFQKeQ4nFOOndnspSIioo5joKIuL1CtwvSh4QCA178/yblURETUYQxURAAeuaMnPJXOyMrX4rvf8sUuh4iIHAwDFREAH3cX07pUy7ZlQ99gELkiIiK6nrLqOqSfuYyP9pzD14cviVqLs6jvTmRHZt4WgY/3nsf5yzX4MuMSJg8JE7skIiICUFdvwNmSKpzIr0RWgRYn8itxokCLQq3OtE9smDfuGdRdtBoZqIiaeCidMXf4TXjlu+NY/sMp3DOoG1QKJ7HLIiLqUkqqdMjKbwxNWflaZBVU4nRRJfQNLc9vDfV1Re8gNQaFedu20N9hoCK6xoPxYVj181nkVdRizb4L+PPtkWKXREQkSfUNBpwtqUZWvhbH87XIagpQxZW6Fvf3VDojKtgTURo1ems8ER3siZuDPOGpUti48pYxUBFdQ6VwwrzEXvjrf37Dip2ncf8toXbzx0pE5Ki0tXpTj9PxvMYAlV1Yibr65vNVZTIg3M8d0U3hKUrjiehgNbr7uEImk4lQffswUBH9zsTY7vj3j2dxtqQa7+46g78mR4ldEhGRQxAEAfkVtabQZPzfnNKaFvd3d3FCVLAafYLViA5WIzrYE701nnBzcbx44ngVE1mZs5McC8ZEY/anh7Dq57O4N647egZ4iF0WEZFdaTAIOFtcheP5WhzL0+JYXgWO52lRVqNvcf8QLxWig9XoG9IYnvqEqBHq4wa53H57nTqCgYqoBYnRgRjeOwA7s4vx0jfH8OlDQ8QuiYhINLX6BpwsrDQFp6O5Wpwo0KJW33zIzkkuQ69AD/RpCk19Qhp7oLzdXESo3HYYqIhaIJPJ8NIf+2LPGz/h51Ml2Hq0AIlR/mKXRURkdTV19cjK1+JorhZHcytwNE+LU4WVqG/hKRJuLk6NvU1NPU99Q7zQK8ijS94hzUBF1Ioefu545I5IvLXjNBZ9dxxDI4eKXRIRkUVpa/U4ntcUnJrC05niKrT0nHhvNwX6hXihb1OvU79uXgj3c4eTRIbsOouBiqgNf7nrJvwnMxe55Vew8sdz4PR0InJUFVf0OJZbgd+avo7mVuD85ZYniweplY3hqVtjgOrXzQshXiq7vstObA4TqEpLS/HYY4/h22+/hVwux8SJE7F8+XJ4eLQ+Wbi2thZPPvkk1q9fD51Oh6SkJLz77rsICgoCAHz88ceYOXNmi8cWFhYiMDAQu3btwvDhw5u9np+fD41GY5mLI7vl6uKEF//QBw9/loFVe87jmf5iV0REdH3aWj2O5lbgt0vXD0/dvF3Rr5sa/btdDVCBniobV+z4HCZQTZkyBfn5+UhLS4Ner8fMmTMxZ84crFu3rtVj5s+fj82bN2Pjxo3w8vJCSkoKJkyYgD179gAA7r//fiQnJ5sdM2PGDNTW1iIwMNBse3Z2NtRqten7379O0jW6TxDu6h2AXdnF+M85Oaa31BdORCSSKl29qefp16YAda6kusV9u/u4on83L/Tr5mX6X193aU8WtxWHCFRZWVnYunUrDh48iMGDBwMA3n77bYwZMwb/+te/EBIS0uyYiooKfPjhh1i3bh1GjBgBAPjoo48QHR2Nffv24dZbb4WrqytcXV1NxxQXF2PHjh348MMPm50vMDAQ3t7e1rlAsmsymQwv/aEvRp/5CScqgI0ZuZiSECF2WUTUBdXqG3AsT4vfLpXj16YA1dqcp+4+rhjQ/ZrwFOIFH4Ynq3GIQJWeng5vb29TmAKAxMREyOVy7N+/H/fcc0+zYzIyMqDX65GYmGjaFhUVhbCwMKSnp+PWW29tdsynn34KNzc33Hvvvc1ei4mJgU6nQ79+/fDSSy9h2LBhrdar0+mg011dOl+r1QIA9Ho99PqW1+e4UcbzWfq8ZK6blwsevysC//rhDP7+v2wk9PRFqI+b2GVJFn+vbYdtbTsdbWt9gwEnC6vwW662ad6TFqeKqlq82y7YS4V+IWr076ZGv25q9AtRw6eFZQq6ys/ZUr/XHTneIQJVQUFBsyE2Z2dn+Pr6oqCgoNVjXFxcmvUqBQUFtXrMhx9+iAcffNCs1yo4OBgrV67E4MGDodPpsGrVKtx1113Yv38/YmNjWzzP4sWL8fLLLzfbvm3bNri5WedDOC0tzSrnpau6CUBPTyecqWzA7A9+RkrfBvDmFuvi77XtsK1tp6W2NghAcS2QUyUzfeVWA3qh+T8yngoBoe4CwjwEhHkAoe4C1C5VAKqA6jxUngTST9rgQhxAZ3+va2pannfWElED1bPPPoslS5a0uU9WVpZNaklPT0dWVhY+++wzs+29e/dG7969Td8PHToUZ86cwRtvvNFsX6MFCxYgNTXV9L1Wq0VoaChGjx5tNg/LEvR6PdLS0jBq1CgoFHzmnDXp9XqU6tLwr6NKnKlsQJF3Hzw0LFzssiSJv9e2w7a2nWvbuqzWgF8uVjQO2zX1PlXW1jc7Rq1yRr9uagzo5oX+TRPHNWol77a7Dkv9XhtHmNpD1ED15JNPYsaMGW3uExkZCY1Gg6KiIrPt9fX1KC0tbfVOO41Gg7q6OpSXl5v1UhUWFrZ4zKpVqxATE4O4uLjr1j1kyBDs3r271deVSiWUSmWz7QqFwmr/YFnz3HSVvwp47u7eeOGb41j6w2mMiNagV5Cn2GVJFn+vbYdtbT1Vunr8dqkCGecvY1u2HIuP7UWBVtdsP6WzHP26eWFAdy8M7O6NAd0b13mSyqNZxNDZ3+uOHCtqoAoICEBAQMB190tISEB5eTkyMjJMgWfHjh0wGAyIj49v8Zi4uDgoFAps374dEydOBNB4p15OTg4SEhLM9q2qqsIXX3yBxYsXt6vuI0eOIDg4uF37kvTcP7gbtmcXY1d2MeZ/cQRfPzoMCie52GURkR2ob5r3dORiOY5cLMORi+U4VXTtpHE5AB3kMuDmIE8M6O6FmFAfDAz1ws1Bnvy3xIE5xByq6OhoJCcnY/bs2Vi5ciX0ej1SUlLwwAMPmO7wy83NxciRI/Hpp59iyJAh8PLywqxZs5CamgpfX1+o1Wo89thjSEhIaDYhfcOGDaivr8fUqVObvfebb76JiIgI9O3bF7W1tVi1ahV27NiBbdu22eTayf7IZDIsmTgAo9/4CUdztVi67SSevZtLfhJ1RQUVtThysQyHc8px+GI5frtUgSv6hmb7hXipMKC7F1wq83D/qHjEhPnBXekQH8HUTg7z01y7di1SUlIwcuRI08Keb731lul1vV6P7Oxsswlkb7zxhmnfaxf2/L0PP/wQEyZMaHFZhLq6Ojz55JPIzc2Fm5sbBgwYgB9++KHFxT6p6whSq/CPe/pj7rpMrPzxDGJCvZHcjwu9EknZlboG/JZbgcM5jT1Ph3PKUaCtbbafh9IZA0Mbh+1iQhu/AtUq6PV6bNmSiyHhvlAoHObjl9rJYX6ivr6+bS7iGR4eDuF3C3GoVCqsWLECK1asaPPce/fubfW1Z555Bs8880zHiqUuYeyAYGRciMDqPefw1MZf0CvIAz0DWl+5n4gchyAIOH+5BodzjL1PZcjKr0TD75YskMuA3ho1BoU1BqdBod7oGeDBeU9dkMMEKiJ7tGBMFI7mVuDA+VI88lkGNs0dxm58IgdUWavHLxcbe58yc8pw+GI5ymuar0EU6KlEbJgPYsIaw1P/7l5wc+HfPDFQEXWKwkmOd6YMwv+9tRuniqrwzH9+xTuTB/GWZiI7ZjAIOFtShcwL5Y3hKaccJ4sqm6027uIsR/9uXhgU6o2YMG/EhvkgmA8IplYwUBF1UqCnCu9NjcX9/96Hzb/mY1CoN/58e6TYZRFRk8paPY5cLEfmhXJk5JThSE4ZtC2s+dTdxxWxYT4Y1BSeooPVcHHmXXfUPgxURBYQ18MXL/xfHyz85hj+sSULPfzcMapPkNhlEXU5giDgXEk1Mi6UITOnHJkXylrsfVIp5BjQ3dsUoAaFeSPQUyVO0SQJDFREFjItoQeO5VXgi0OXkLIuE+tmxyOuh6/YZRFJ2pW6BvxyqbwxQF1onP9U1sLcp+4+rojr4YPYsMavqGCu+USWxUBFZCEymQz/uKc/SqrqsONEER76+BD+85cE3BTIldSJLCWv/AoyLpQ19UCV4XiettnDgl2c5RjQzQuxxgDVg71PZH0MVEQW5Owkx4oHY/Hgqn04nFOOaR8ewFePDoPGi/+YE3WUvsGArHwtMi6U4VBTD1R+RfN1n4LUSgzu4YtBYd6I6+GDviFenPtENsdARWRhri5O+HD6Lbh35V6cLa7G9NUH8MXDCfBy43PSiNpSXlOHzJwyHDrf2AP1y6Vy1OoNZvs4yWXoE6xuHL7r4YO4Hj4I4Z13ZAcYqIiswNfdBZ8+NAQT3t2L7MJKTFu9H588NATebi5il0ZkFwRBwNmmyeMZ58uQkVOG00VVzfbzclU0zX3yRlwPXwwM5bpPZJ/4W0lkJd193PDprCGY/P4+/HKpApM/2I81s4bAz0MpdmlENlerb3xsi7H3KTOnDKXVdc32iwxwR1yYDwaHN/Y+Rfpz1XFyDAxURFYUpVFjw8MJePCD/cjK1+L+9/dh3Z/jEajmnCqStpIqXVN4KsWhC2U4mlsBfUPzyeMDu3shrocvBjcN4fm6sxeXHBMDFZGV3RzkiS8evhVTVu3H6aIq3PfvdKydfSu6ebuKXRqRRRgMAs4UV+HQhTJTiDp/uabZfv4eLojr4YPBPXwRF+6Dfpw8ThLCQEVkA5EBHvji4QRM/mAfzl+uwX0r07F6xi3oreGSCuR4avUN+OViOQ41LV+QcaEMFVear/10c5CHqfdpcLgPwnzdOHmcJIuBishGQn3d8MXDCZiyaj/OlVRj4nt78dbkGIyI4orqZN+KKmuRcb5x6YJDF8pwLLei2dpPKoUcMaHept6n2FAf3tlKXQoDFZENhXi74qu/DMUjazKw/1wpZn1yCH8bE41Zt0Xw/7mTXWgwCDhVVGmaPJ5xoQw5pc2H7wI9lU0Txxt7oPqEqLnyOHVpDFRENubj7oLPZsVj4TdH8fmBi3h1cxZOFlbi1fH9OZ+EbK5aV4/sChnO7jyDw5e0OHyhDJU68wcHy2RA7yDPxvlP4Y1zoLr7uPL/BBBdg4GKSAQuznL8457+uCnQE3/ffBxfHLqE7MIqvPVADHr4uYtdHkmUIAjIvebRLRkXypCVr4VBcAKOnzHt5+bi1LTquC/iejQ+PFit4vAdUVsYqIhEIpPJMOu2CEQGuGPe54fxy8VyjFn+M14Z1w8TYrvx//1Tp9XVG3Asr8K07lPGhTIUanXN9vNxETCsdzBuifBDXA8fRGk84czhO6IOYaAiEtnw3oH43xN3YP76IzhwvhRPbvwFP54sxqv39GOvAHVIUWUtMi+UIzOn8bl3v+ZWoK7e/NEtznIZ+oaoTY9tGRDiicN7dmDMmAFQKPj7RnSjGKiI7EA3b1d8PudWvLvzNN7cfgrf/JKHjAtleHV8PwyPChS7PLJD+gYDTuRXNoanpq+LpVea7efjprj63LswHwzo7g1XF6er59HrcdiWhRNJFAMVkZ1wksvw2MheGNbLH0+sP4Kc0hrM/Pggkvtq8OIf+iCEC4F2aUXaWmTmlOPwxTIcvlCOX3ObPzhYJgNuDvRErOnZdz6I8Hfn8DGRDTBQEdmZ2DAf/G/e7Xjzh5NYvec8th4rwE+nijE/8WbMGBbOW9O7gFp9A47lVeBwTjkO55TjyMVy5JY3731Sq5wxKMwHsWE+iO3hjYGhnDxOJBYGKiI75K50xt/G9sHEuO54/uujOHShDH/fkoXPD+bgyVG9cXc/DR8YKxEGg4CzJVU4crECRy6W4ZeLFcjK1zZbOFMua3yMUWOA8sagMB9E+rvz94DITjBQEdmxKI0aXzycgC8zLmHx/7Jwtrgac9dlok+wGk8l3YzhvQM5nONABEFAfkUtfrlYjl8uVeCXi+U4mlvRbN0nAPD3UGJQmDdiQr0xKMwbA7p7w0PJf7KJ7BX/OonsnFwuw323hOLu/hp8uPscVv18DsfztXjo40OIDfPGI3f2xMjoIDixp8LuFFXW4rdLFfj1UgV+vVSO33IrUFJV12w/lUKO/t28EBPqjZhQHwwM9UI3by6cSeRIGKiIHISnSoEnEm/G9IRwrPzpDD7Zex6ZOeWY81kGwnzdMGNoOCYN7g5PzqGxOUEQUKCtxbFcLX7LrcDR3Ar8lluBosrmaz45yWXoHeSJgaFeGNi9sefp5iAPrvtE5OAYqIgcjI+7CxbcHY1ZwyLw0d7zWLc/BzmlNXjlu+NYlnYSE2K74Z5B3RAT6s0eDitoMAg4V1KF4/mVOJZXgeN5WhzL06K0unnPk0wG9AzwwIDuXhjQzQsDQr3RJ1gNlcKphTMTkSNjoCJyUIFqFf6aHIXHR/TCV4cv4aM953G6qAqfpl/Ap+kXEOnvjvGDGsNVqK+b2OU6pNLqOpwo0CK7oBLZBZXIytfiREEldL9bLBNo7HnqFeiBviFe6N9NjX7dvNAnRA03F/4zS9QV8C+dyMG5ujhhSnwPPDgkDLtPl+A/GZfw/bFCnC2pxrK0k1iWdhJ9Q9QYGRWIEdFBGNDNi3eG/U7FFT1OF1XiZGEVThVW4VRRY4BqacgOaHzWXW+NJ/oEq9E3xAt9Q9TorfFkzxNRF8ZARSQRMpkMt/cKwO29AlClq8fWowX4+vAl7D1zGceahqXe2nEa/h5K3HGzP4aE++KWCF9EdpGFH+sbDMgtv4JzJdU4W1yNM8VVTV/VKG4lOAFAqK8regepEaXxRHSwGn1C1Ojh68ZQSkRmGKiIJMhD6Yx747rj3rjuuFylw87sYuw4UYifTpagpEqHrzJz8VVmLgDA38MFg3v4on/3xiGqvsFqBHgqHTJkVdbqcbH0Ci6W1eBiaQ0ulV3BhcvVOH+58fvfr+10rWAvFXoFeaJXoAduDvJAryBP3BzkyaUKiKhd+C8FkcT5eShN4aqu3oAD50qRfrYEB8+V4cilcpRU1WHrsQJsPVZgOsbfwwU3B3mih587wv3c0MPPDWG+7gj2UsHbTWHzsFVXb0BZTR2KtDoUV9WiSKtDUaUOBdpa5JVfQX55LfIqrqCytvl6TtdSOsvRw88Nkf4e6Bnojp4BHogM8EBkgDtXGCeiTmGgIupCXJzluK2XP27r5Q+g8REnv+VWIONCGY7naXE8X4uzxVUoqapDSdVl7D1zufk5nOQI8FQiwFMJfw8l1CpneKqc4alSwFPlDFcXJyic5FA4yeHiLIdCLoMAwCAIEARAAKCvN0BXb4CuvgG6egOu1DWgWlePytp6VOnqob1Shwv5Tnj9xM+oqNG3uPBla3zcFAjzdUN3XzeE+rghzNcN4f5uCPdzh0at4lAdEVkFA5UNCELjMINWq7X4ufV6PWpqaqDVaqFQ8P9hW5NU27q3rzN6+wYAgwIANIasU4WVOFtcjYulNcgpq0FO6RVcKq1G+ZV61AK4WFOFi4W2qO7q8+vkMsDP3QX+TWEuwEOJAE8VNGolgr1dofFSQqN2hXurQ3R6VFXpbVG0Q5Hq77U9YlvbjqXa2vi5bfwcbwsDlQ1UVlYCAEJDQ0WuhMixXRC7ACLqkiorK+Hl5dXmPjKhPbGLOsVgMCAvLw+enp4Wn3ui1WoRGhqKixcvQq1WW/TcZI5tbTtsa9thW9sO29p2LNXWgiCgsrISISEhkMvbfpoBe6hsQC6Xo3v37lZ9D7VazT9QG2Fb2w7b2nbY1rbDtrYdS7T19XqmjPjwKCIiIqJOYqAiIiIi6iQGKgenVCqxcOFCKJVKsUuRPLa17bCtbYdtbTtsa9sRo605KZ2IiIiok9hDRURERNRJDFREREREncRARURERNRJDFREREREncRA5cBWrFiB8PBwqFQqxMfH48CBA2KXJEmLFy/GLbfcAk9PTwQGBmL8+PHIzs4WuyzJe+211yCTyfDEE0+IXYpk5ebmYurUqfDz84Orqyv69++PQ4cOiV2W5DQ0NOCFF15AREQEXF1d0bNnTyxatKhdz4ejtv3000/4wx/+gJCQEMhkMmzatMnsdUEQ8OKLLyI4OBiurq5ITEzEqVOnrFILA5WD2rBhA1JTU7Fw4UJkZmZi4MCBSEpKQlFRkdilSc6PP/6IuXPnYt++fUhLS4Ner8fo0aNRXV0tdmmSdfDgQfz73//GgAEDxC5FssrKyjBs2DAoFAr873//w/Hjx7F06VL4+PiIXZrkLFmyBO+99x7eeecdZGVlYcmSJfjnP/+Jt99+W+zSHF51dTUGDhyIFStWtPj6P//5T7z11ltYuXIl9u/fD3d3dyQlJaG2ttbyxQjkkIYMGSLMnTvX9H1DQ4MQEhIiLF68WMSquoaioiIBgPDjjz+KXYokVVZWCr169RLS0tKEO++8U5g3b57YJUnSX//6V+G2224Tu4wuYezYscJDDz1ktm3ChAnClClTRKpImgAIX3/9tel7g8EgaDQa4fXXXzdtKy8vF5RKpfD5559b/P3ZQ+WA6urqkJGRgcTERNM2uVyOxMREpKeni1hZ11BRUQEA8PX1FbkSaZo7dy7Gjh1r9vtNlvfNN99g8ODBmDRpEgIDAzFo0CB88MEHYpclSUOHDsX27dtx8uRJAMAvv/yC3bt34+677xa5Mmk7d+4cCgoKzP4t8fLyQnx8vFU+K/lwZAdUUlKChoYGBAUFmW0PCgrCiRMnRKqqazAYDHjiiScwbNgw9OvXT+xyJGf9+vXIzMzEwYMHxS5F8s6ePYv33nsPqampeO6553Dw4EE8/vjjcHFxwfTp08UuT1KeffZZaLVaREVFwcnJCQ0NDfj73/+OKVOmiF2apBUUFABAi5+VxtcsiYGKqAPmzp2Lo0ePYvfu3WKXIjkXL17EvHnzkJaWBpVKJXY5kmcwGDB48GD84x//AAAMGjQIR48excqVKxmoLOyLL77A2rVrsW7dOvTt2xdHjhzBE088gZCQELa1hHDIzwH5+/vDyckJhYWFZtsLCwuh0WhEqkr6UlJS8N1332Hnzp3o3r272OVITkZGBoqKihAbGwtnZ2c4Ozvjxx9/xFtvvQVnZ2c0NDSIXaKkBAcHo0+fPmbboqOjkZOTI1JF0vX000/j2WefxQMPPID+/fvjT3/6E+bPn4/FixeLXZqkGT8PbfVZyUDlgFxcXBAXF4ft27ebthkMBmzfvh0JCQkiViZNgiAgJSUFX3/9NXbs2IGIiAixS5KkkSNH4rfffsORI0dMX4MHD8aUKVNw5MgRODk5iV2ipAwbNqzZ8h8nT55Ejx49RKpIumpqaiCXm3/cOjk5wWAwiFRR1xAREQGNRmP2WanVarF//36rfFZyyM9BpaamYvr06Rg8eDCGDBmCN998E9XV1Zg5c6bYpUnO3LlzsW7dOvz3v/+Fp6enaezdy8sLrq6uIlcnHZ6ens3mpbm7u8PPz4/z1axg/vz5GDp0KP7xj3/gvvvuw4EDB/D+++/j/fffF7s0yfnDH/6Av//97wgLC0Pfvn1x+PBhLFu2DA899JDYpTm8qqoqnD592vT9uXPncOTIEfj6+iIsLAxPPPEEXn31VfTq1QsRERF44YUXEBISgvHjx1u+GIvfN0g28/bbbwthYWGCi4uLMGTIEGHfvn1ilyRJAFr8+uijj8QuTfK4bIJ1ffvtt0K/fv0EpVIpREVFCe+//77YJUmSVqsV5s2bJ4SFhQkqlUqIjIwU/va3vwk6nU7s0hzezp07W/z3efr06YIgNC6d8MILLwhBQUGCUqkURo4cKWRnZ1ulFpkgcKlWIiIios7gHCoiIiKiTmKgIiIiIuokBioiIiKiTmKgIiIiIuokBioiIiKiTmKgIiIiIuokBioiIiKiTmKgIiIiIuokBioiIiKiTmKgIiIiIuokBioiohvw6aefws/PDzqdzmz7+PHj8ac//UmkqohILAxUREQ3YNKkSWhoaMA333xj2lZUVITNmzfjoYceErEyIhIDAxUR0Q1wdXXFgw8+iI8++si0bc2aNQgLC8Ndd90lXmFEJAoGKiKiGzR79mxs27YNubm5AICPP/4YM2bMgEwmE7kyIrI1mSAIgthFEBE5qri4ONx7770YPXo0hgwZgvPnzyM0NFTssojIxpzFLoCIyJH9+c9/xptvvonc3FwkJiYyTBF1UeyhIiLqhIqKCoSEhKC+vh6ffvop7r//frFLIiIRcA4VEVEneHl5YeLEifDw8MD48ePFLoeIRMJARUTUSbm5uZgyZQqUSqXYpRCRSDjkR0R0g8rKyrBr1y7ce++9OH78OHr37i12SUQkEk5KJyK6QYMGDUJZWRmWLFnCMEXUxbGHioiIiKiTOIeKiIiIqJMYqIiIiIg6iYGKiIiIqJMYqIiIiIg6iYGKiIiIqJMYqIiIiIg6iYGKiIiIqJMYqIiIiIg6iYGKiIiIqJP+H9pNTHjfK4JmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = np.arange(0, 10, 0.1)\n",
    "f = y * (1 - y) / (1 + y) ** 3\n",
    "\n",
    "plt.plot(y, f)\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('f(y)')\n",
    "plt.title('f(y) = y(1 - y)/(1 + y)^3')\n",
    "\n",
    "max_abs_f = np.max(np.abs(f))\n",
    "plt.ylim(-max_abs_f, max_abs_f)\n",
    "plt.grid()\n",
    "\n",
    "print('La valeur maximale de |f(y)| est', max_abs_f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc, comme $\\sup_{y \\in (0, \\infty)} |f(y)| \\approx 0.096221 \\le 1$, on a $|h'(t)| \\le 1$ pour tout $t \\in \\mathbb{R}$, et donc $h$ est 1-Lipschitzienne sur $\\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4. Déterminer la vraisemblance et la log-vraisemblance du modèle\n",
    "\n",
    "La vraisemblance du modèle est donnée par\n",
    "\n",
    "$$\\begin{align*}\n",
    "L_n(\\theta) &= \\prod_{i=1}^n \\mathbb{P}_\\theta(Y_i = y_i) \\\\\n",
    "&= \\prod_{i=1}^n \\varphi(\\theta^T \\mathbf{x}_i)^{y_i} (1 - \\varphi(\\theta^T \\mathbf{x}_i))^{1-y_i} \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Donc la log-vraisemblance est donnée par\n",
    "$$\\begin{align*}\n",
    "\\ell_n(\\theta) &= \\log L_n(\\theta) \\\\\n",
    "&= \\sum_{i=1}^n y_i \\log \\varphi(\\theta^T \\mathbf{x}_i) + (1-y_i) \\log (1 - \\varphi(\\theta^T \\mathbf{x}_i)) \\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5. Montrer que la log-vraisemblance est strictement concave\n",
    "\n",
    "On a\n",
    "$$\\nabla_\\theta ~ \\varphi(\\theta^T x_i) = \\varphi'(\\theta^T x_i) ~ x_i,$$\n",
    "\n",
    "donc, comme $\\varphi' = \\varphi(1 - \\varphi) = h$, on a\n",
    "$$\\begin{align*}\n",
    "\\nabla_\\theta ~ \\ell_n(\\theta) &= \\sum_{i=1}^n \\left( y_i \\frac{\\varphi'(\\theta^T x_i)}{\\varphi(\\theta^T x_i)} - (1-y_i) \\frac{\\varphi'(\\theta^T x_i)}{1 - \\varphi(\\theta^T x_i)} \\right) x_i \\\\\n",
    "&= \\sum_{i=1}^n \\left( \\frac{y_i (1 - \\varphi(\\theta^T x_i)) - (1-y_i) \\varphi(\\theta^T x_i)}{h(\\theta^T x_i)} \\right) \\varphi'(\\theta^T x_i) x_i \\\\\n",
    "&= \\sum_{i=1}^n \\left( \\frac{y_i - \\varphi(\\theta^T x_i)}{h(\\theta^T x_i)} \\right) \\varphi'(\\theta^T x_i) x_i \\\\\n",
    "&= \\sum_{i=1}^n \\left( y_i - \\varphi(\\theta^T x_i) \\right) x_i \\\\\n",
    "&= X_n^T (Y_n - \\Phi_n (\\theta)),\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer la hessienne, on pose $\\nabla_\\theta ~ \\ell_n(\\theta) = (f_1, \\ldots, f_p)^T$. La hessienne est donnée par $\\nabla^2_\\theta ~ \\ell_n(\\theta) = \\left( \\frac{\\partial f_i}{\\partial \\theta_j} \\right)_{1 \\le i, j \\le p} = \\left( (\\nabla_\\theta f_i)^T \\right)_{1 \\le i \\le p}^T$.\n",
    "\n",
    "$$\\begin{align*}\n",
    "f_i &= \\sum_{j=1}^n (y_j - \\varphi(\\theta^T x_j)) x_{j, i} \\\\\n",
    "\\implies \\nabla_\\theta ~ f_i &= \\sum_{j=1}^n \\left( -\\varphi'(\\theta^T x_j) x_{j, i} \\right) x_j \\\\\n",
    "\\implies \\nabla_\\theta ~ f_i^T &= \\sum_{j=1}^n \\left( -\\varphi'(\\theta^T x_j) x_{j, i} \\right) x_j^T \\\\\n",
    "\\implies \\nabla^2_\\theta ~ \\ell_n(\\theta) &= - \\sum_{j=1}^n \\varphi'(\\theta^T x_j) x_j x_j^T \\\\\n",
    "&= - \\sum_{j=1}^n h(\\theta^T x_j) x_j x_j^T \\\\\n",
    "&= - F_n(\\theta),\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule maintenant $\\mathbb{E}_{n, \\theta} \\left[ \\nabla_\\theta \\ell_n(\\theta) ~ \\nabla_\\theta \\ell_n(\\theta)^T \\right]$.\n",
    "\n",
    "$$\\nabla_\\theta \\ell_n(\\theta) ~ \\nabla_\\theta \\ell_n(\\theta)^T = X_n^T (Y_n - \\Phi_n(\\theta)) (Y_n - \\Phi_n(\\theta))^T X_n$$\n",
    "\n",
    "$$\\mathbb{E}_{n, \\theta} (Y_n) = \\Phi_n(\\theta)$$\n",
    "\n",
    "$$\\begin{align*}\n",
    "(\\mathbb{E}_{n, \\theta} (Y_n Y_n^T))_{ij} &= \\mathbb{E}_{n, \\theta} (Y_i ~ Y_j) \\\\\n",
    "&= \\mathbb{E}_{n, \\theta} (Y_i) \\mathbb{E}_{n, \\theta} (Y_j) (1 - \\delta_{ij}) + \\mathbb{E}_{n, \\theta} (Y_i^2) \\delta_{ij} \\\\\n",
    "&= \\mathbb{E}_{n, \\theta} (Y_i) \\mathbb{E}_{n, \\theta} (Y_j) (1 - \\delta_{ij}) + \\mathbb{E}_{n, \\theta} (Y_i) \\delta_{ij} \\\\\n",
    "&= \\varphi(\\theta^T x_i) \\varphi(\\theta^T x_j) (1 - \\delta_{ij}) + \\varphi(\\theta^T x_i) \\delta_{ij} \\\\\n",
    "&= \\varphi(\\theta^T x_i) \\varphi(\\theta^T x_j) + \\delta_{ij} \\varphi(\\theta^T x_i) (1 - \\varphi(\\theta^T x_i)) \\\\\n",
    "&= \\varphi(\\theta^T x_i) \\varphi(\\theta^T x_j) + \\delta_{ij} h(\\theta^T x_i) \\\\\n",
    "\\implies \\mathbb{E}_{n, \\theta} (Y_n Y_n^T) &= \\Phi_n(\\theta) \\Phi_n(\\theta)^T + \\mathrm{diag}(h(\\theta^T x_1), \\ldots, h(\\theta^T x_n)) \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathbb{E}_{n, \\theta} \\left[ (Y_n - \\Phi_n(\\theta)) (Y_n - \\Phi_n(\\theta))^T \\right] &= \\mathbb{E}_{n, \\theta} (Y_n Y_n^T) - \\mathbb{E}_{n, \\theta} (Y_n) \\Phi_n(\\theta)^T - \\Phi_n(\\theta) \\mathbb{E}_{n, \\theta} (Y_n)^T + \\Phi_n(\\theta) \\Phi_n(\\theta)^T \\\\\n",
    "&= \\mathbb{E}_{n, \\theta} (Y_n Y_n^T) - \\Phi_n(\\theta) \\Phi_n(\\theta)^T \\\\\n",
    "&= \\mathrm{diag}(h(\\theta^T x_1), \\ldots, h(\\theta^T x_n)) \\\\\n",
    "&= \\colon H_n(\\theta),\n",
    "\\end{align*}$$\n",
    "\n",
    "Donc,\n",
    "$$\\begin{align*}\n",
    "\\mathbb{E}_{n, \\theta} \\left[ \\nabla_\\theta \\ell_n(\\theta) ~ \\nabla_\\theta \\ell_n(\\theta)^T \\right] &= X_n^T H_n(\\theta) X_n \\\\\n",
    "&= (x_1, \\ldots, x_n) H_n(\\theta) (x_1, \\ldots, x_n)^T \\\\\n",
    "&= \\sum_{i=1}^n h(\\theta^T x_i) x_i x_i^T \\\\\n",
    "&= F_n(\\theta),\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme la hessienne est négative définie, la log-vraisemblance est strictement concave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\varphi(\\lambda \\theta_\\star) = \\frac 1 {1 + e^{-\\lambda \\theta_\\star^T x_i}}$$\n",
    "\n",
    "Si $y_i = 1$, on a $\\theta_\\star^T x_i > 0$, et alors $\\lim_{\\lambda \\to \\infty} \\varphi(\\lambda \\theta_\\star) = 1$.\n",
    "\n",
    "Si $y_i = 0$, on a $\\theta_\\star^T x_i < 0$, et alors $\\lim_{\\lambda \\to \\infty} \\varphi(\\lambda \\theta_\\star) = 0$.\n",
    "\n",
    "Dans les deux cas, on a\n",
    "$$\\lim_{\\lambda \\to \\infty} y_i \\log \\varphi(\\lambda \\theta_\\star^T x_i) + (1-y_i) \\log (1 - \\varphi(\\lambda \\theta_\\star^T x_i)) = 0,$$\n",
    "\n",
    "et en sommant sur $i$, on obtient $\\lim_{\\lambda \\to \\infty} \\ell_n(\\lambda \\theta_\\star) = 0$.\n",
    "\n",
    "D'une part, comme $\\ell_n(\\theta) \\le 0$ pour tout $\\theta$, on a $\\sup_{\\theta} \\ell_n(\\theta) = 0$.\n",
    "D'autre part, si on avait un maximum de vraisemblance $\\hat{\\theta}$, on aurait $\\ell_n(\\hat{\\theta}) = \\sup_{\\theta} \\ell_n(\\theta) = 0$, mais ça ne peut pas arriver, car $\\varphi(\\theta^T x_i) \\in (0,1) \\implies \\log \\varphi(\\theta^T x_i) \\in (-\\infty, 0)$ et $\\log (1 - \\varphi(\\theta^T x_i)) \\in (-\\infty, 0)$, donc $\\ell_n(\\theta) < 0$ pour tout $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7. Montrer que si les données sont quasi-séparables, alors le maximum de vraisemblance n'existe pas non plus\n",
    "\n",
    "Soient $\\mathcal E_0 = \\{k \\in \\{1, \\ldots, n\\} \\mid y_k = 0\\}$ et $\\mathcal E_1 = \\{k \\in \\{1, \\ldots, n\\} \\mid y_k = 1\\}$.\n",
    "\n",
    "On a\n",
    "\n",
    "$$\\begin{align*}\n",
    "L_n(\\theta_\\lambda) &= \\prod_{k \\in \\mathcal E_0} (1 - \\varphi(\\theta_\\lambda^T x_k)) \\\\\n",
    "&\\times \\prod_{k \\in \\mathcal E_1} \\varphi(\\theta_\\lambda^T x_k) \\\\\n",
    "&\\times \\prod_{k \\in \\mathcal E} \\varphi(\\theta_\\lambda^T x_k)^{y_k} (1 - \\varphi(\\theta_\\lambda^T x_k))^{1-y_k} \\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour $k \\in \\mathcal E$,\n",
    "\n",
    "$$\\varphi(\\theta_\\lambda^T x_k)^{y_k} (1 - \\varphi(\\theta_\\lambda^T x_k))^{1-y_k}$$\n",
    "\n",
    "ne dépend pas de $\\lambda$, car\n",
    "\n",
    "$$\\varphi(\\theta_\\lambda^T x_k) = \\varphi(\\lambda \\theta_\\star^T x_k + (\\bar \\theta - \\theta_\\star)^T x_k)\n",
    "= \\varphi((\\bar \\theta - \\theta_\\star)^T x_k).$$\n",
    "\n",
    "Donc, on peut ignorer ces termes.\n",
    "\n",
    "Pour $k \\in \\mathcal E_1$, on a $\\theta_\\star^T x_k > 0$.\n",
    "Dans ce cas,\n",
    "$\\varphi$ étant strictement croissante, on a $\\lambda \\mapsto \\varphi(\\theta_\\lambda^T x_k) = \\varphi(\\lambda \\theta_\\star^T x_k + (\\bar \\theta - \\theta_\\star)^T x_k)$ strictement croissante.\n",
    "\n",
    "De même, pour $k \\in \\mathcal E_0$, on a $\\theta_\\star^T x_k < 0$ et $\\lambda \\mapsto \\varphi(\\theta_\\lambda^T x_k)$ strictement décroissante, et alors $\\lambda \\mapsto 1 - \\varphi(\\theta_\\lambda^T x_k)$ strictement croissante.\n",
    "\n",
    "Cela démontre que $L_n(\\theta_\\lambda)$ est strictement croissante en $\\lambda$, dès que $\\mathcal E_0 \\cup \\mathcal E_1 \\ne \\emptyset$.\n",
    "\n",
    "Comme $\\bar \\theta$ était arbitraire, on peut pour tout point $\\theta = \\bar \\theta - \\theta_\\star \\in \\mathbb{R}^p$ trouver un $\\theta_\\lambda$ tel que $L_n(\\theta_\\lambda) > L_n(\\theta)$, et donc le maximum de vraisemblance n'existe pas, dès que les données soient quasi-séparables et que $\\mathcal E_0 \\cup \\mathcal E_1 \\ne \\emptyset$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8. Montrer que l'existence d'un récouvrement implique l'existence et l'unicité du maximum de vraisemblance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour $\\theta \\in \\mathbb{R}^p \\setminus \\{0\\}$, $(\\theta^T x_1, \\ldots, \\theta^T x_n)$ a toujours des éléments de signes opposés, donc \n",
    "$f(\\theta) = \\min\\limits_{1 \\le i \\le n} \\theta^T x_i < 0$ et $g(\\theta) = \\max\\limits_{1 \\le i \\le n} \\theta^T x_i > 0$. Comme $f$ est le $\\min$ de fonctions continues et $g$ est le $\\max$ de fonctions continues, $f$ et $g$ sont continues.\n",
    "\n",
    "Sur le compact $\\mathcal S(0,1)$, $f$ et $g$ atteignent leurs bornes, donc il existent $\\theta_0, \\theta_1 \\in \\mathcal S(0,1)$ tels que \n",
    "\n",
    "$$\\begin{cases}\n",
    "f(\\theta) \\le f(\\theta_0) < 0 \\\\\n",
    "g(\\theta) \\ge g(\\theta_1) > 0\n",
    "\\end{cases}$$\n",
    "\n",
    "pour tout $\\theta \\in \\mathcal S(0,1)$. On prend $\\zeta = \\frac 1 2 \\min\\{|f(\\theta_0)|, |g(\\theta_1)|\\}$, et on a $\\zeta > 0$, avec\n",
    "\n",
    "$$\\begin{cases}\n",
    "f(\\theta) < -\\zeta \\\\\n",
    "g(\\theta) > \\zeta\n",
    "\\end{cases}$$\n",
    "\n",
    "pour tout $\\theta \\in \\mathcal S(0,1)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9. Montrer qu'il existe une constante $C$ telle que pour tout $\\theta, \\vartheta \\in \\mathbb{R}^p$, et tout $n > 0$, $F_n$ soit $Cn$-Lipschitzienne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut estimer\n",
    "\n",
    "$$\\lVert F_n(\\theta) - F_n(\\vartheta) \\rVert = \\sup\\limits_{\\lVert w \\rVert = 1} \\lVert \\left[F_n(\\theta) - F_n(\\vartheta)\\right] w \\rVert.$$\n",
    "\n",
    "Pour $w \\in \\mathbb{R}^p$ avec $\\lVert w \\rVert = 1$, on a\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\lVert \\left[F_n(\\theta) - F_n(\\vartheta)\\right] w \\rVert &= \\left\\lVert \\sum_{i=1}^n [h(\\theta^T x_i) - h(\\vartheta^T x_i)] x_i x_i^T w \\right\\rVert \\\\\n",
    "&\\le \\sum_{i=1}^n \\left\\lVert [h(\\theta^T x_i) - h(\\vartheta^T x_i)] x_i x_i^T w \\right\\rVert \\\\\n",
    "&= \\sum_{i=1}^n |x_i^T w| \\cdot |h(\\theta^T x_i) - h(\\vartheta^T x_i)| \\cdot \\lVert x_i \\rVert \\\\\n",
    "&\\le \\sum_{i=1}^n \\lVert x_i \\rVert \\cdot \\lVert x_i \\rVert \\cdot \\lVert w \\rVert \\cdot |h(\\theta^T x_i) - h(\\vartheta^T x_i)| &\\quad \\text{(Cauchy-Schwarz)} \\\\\n",
    "&= \\sum_{i=1}^n \\lVert x_i \\rVert^2 \\cdot |h(\\theta^T x_i) - h(\\vartheta^T x_i)| &\\quad \\text{(car $\\lVert w \\rVert = 1$)} \\\\\n",
    "&\\le \\sum_{i=1}^n \\lVert x_i \\rVert^2 \\cdot | (\\theta - \\vartheta)^T x_i | &\\quad \\text{(car $h$ est 1-Lipschitzienne)} \\\\\n",
    "&\\le \\lVert \\theta - \\vartheta \\rVert \\sum_{i=1}^n \\lVert x_i \\rVert^3 &\\quad \\text{(Cauchy-Schwarz)} \\\\\n",
    "&= n \\cdot \\lVert \\theta - \\vartheta \\rVert \\cdot \\frac 1 n \\sum_{i=1}^n \\lVert x_i \\rVert^3 \\\\\n",
    "&\\le Cn \\cdot \\lVert \\theta - \\vartheta \\rVert,\n",
    "\\end{align*}$$\n",
    "\n",
    "où $C := \\sup\\limits_{n > 0} \\frac 1 n \\sum_{i=1}^n \\lVert x_i \\rVert^3 < \\infty$ par hypothèse.\n",
    "\n",
    "On a bien montré que, pour tout $w \\in \\mathbb{R}^p$ avec $\\lVert w \\rVert = 1$, $$\\lVert \\left[F_n(\\theta) - F_n(\\vartheta)\\right] w \\rVert \\le Cn \\lVert \\theta - \\vartheta \\rVert.$$ En prenant le $\\sup$ sur ces $w$, on obtient $\\lVert F_n(\\theta) - F_n(\\vartheta) \\rVert \\le Cn \\lVert \\theta - \\vartheta \\rVert$, ce qui montre que $F_n$ est $Cn$-Lipschitzienne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Comme $$\\nabla \\ell_n(\\theta) = \\sum_{i=1}^n \\left\\{y_i - \\varphi(\\theta^T x_i)\\right\\} x_i,$$ on a \n",
    "$$\\nabla \\ell_n(\\hat \\theta_{n}) - \\nabla \\ell_n(\\theta) = - \\sum_{i=1}^n \\left\\{ \\varphi(\\hat \\theta_{n}^T x_i) - \\varphi(\\theta^T x_i) \\right\\} x_i.$$\n",
    "\n",
    "On fait un développement limité d'ordre 1:\n",
    "\n",
    "$$\\varphi(t) = \\varphi(t_0) + \\varphi'(t_0) (t - t_0) + R(t) (t - t_0), \\quad \\text{avec} \\quad \\lim_{t \\to t_0} R(t) = 0.$$\n",
    "\n",
    "Donc, pour $t = \\hat \\theta_{n}^T x_i$ et $t_0 = \\theta^T x_i$,\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\varphi(\\hat \\theta_{n}^T x_i) - \\varphi(\\theta^T x_i) &= \\varphi'(\\theta^T x_i) (\\hat \\theta_{n}^T x_i - \\theta^T x_i) + R(\\hat \\theta_{n}^T x_i) (\\hat \\theta_{n}^T x_i - \\theta^T x_i) \\\\\n",
    "&= \\left[ \\varphi'(\\theta^T x_i) + R(\\hat \\theta_{n}^T x_i) \\right] (\\hat \\theta_{n} - \\theta)^T x_i \\\\\n",
    "&= \\left[ h(\\theta^T x_i) + R(\\hat \\theta_{n}^T x_i) \\right] x_i^T (\\hat \\theta_{n} - \\theta).\n",
    "\\end{align*}$$\n",
    "\n",
    "Donc, on a\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\left\\{\\varphi(\\hat \\theta_{n}^T x_i) - \\varphi(\\theta^T x_i) \\right\\} x_i &= \\left\\{h(\\theta^T x_i) + R(\\hat \\theta_{n}^T x_i) \\right\\} x_i x_i^T (\\hat \\theta_{n} - \\theta) \\\\\n",
    "\\implies \\nabla \\ell_n(\\hat \\theta_{n}) - \\nabla \\ell_n(\\theta) &= - \\sum_{i=1}^n \\left\\{ \\varphi(\\hat \\theta_{n}^T x_i) - \\varphi(\\theta^T x_i) \\right\\} x_i \\\\\n",
    " &= - \\sum_{i=1}^n \\left\\{h(\\theta^T x_i) + R(\\hat \\theta_{n}^T x_i) \\right\\} x_i x_i^T (\\hat \\theta_{n} - \\theta) \\\\\n",
    "&= \\left[ - F_n(\\theta) - \\sum_{i=1}^n R(\\hat \\theta_{n}^T x_i) x_i x_i^T \\right] (\\hat \\theta_{n} - \\theta).\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc, si on appele $R_n := \\frac 1 n \\sum_{i=1}^n R(\\hat \\theta_{n}^T x_i) x_i x_i^T$, on a, par la consistance de la suite d'estimateurs $\\{ \\hat \\theta_{n} \\}_{n \\ge 1}$, $\\lim_{n \\to \\infty} R_n = 0$, et donc\n",
    "\n",
    "$$\\frac { \\nabla \\ell_n(\\hat \\theta_{n}^{\\mathrm{MV}}) - \\nabla \\ell_n(\\theta) } { \\sqrt n } =  \\left( - \\frac {F_n(\\theta)} n + R_n \\right) \\sqrt n (\\hat \\theta_{n} - \\theta)$$\n",
    "\n",
    "où $R_n \\xrightarrow[]{\\mathbb{P}_{n, \\theta}\\text{-prob}} 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Soient $Z_{n, i} = \\frac 1 {\\sqrt n} (Y_i - \\varphi(\\theta^T x_i)) x_i$. Les variables $\\{(Z_{n, i})_{i = 1}^n, n \\in \\mathbb{N}\\}$ forment un tableau triangulaire de variables aléatoires indépendantes, centrées, de carré intégrable (donné par $\\mathbb{E} (\\lVert Z_{n, i} \\rVert^2) = h(\\theta^T x_i) \\lVert x_i \\rVert^2$). On veut appliquer le Lindeberg-Feller, que nous dira que\n",
    "\n",
    "$$\\frac 1 {\\sqrt n} \\nabla \\ell_n(\\theta) = \\sum_{i=1}^n Z_{n, i} \\xrightarrow[]{\\mathrm{loi}} \\mathcal N(0, Q(\\theta)).$$\n",
    "\n",
    "Vérifions les conditions de Lindeberg-Feller:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Première condition\n",
    "\n",
    "Soit $\\varepsilon > 0$ et $n \\in \\mathbb{N}$. On a\n",
    "\n",
    "$$\\lVert Z_{n, i} \\rVert^2 = \\frac 1 n (Y_i - \\varphi(\\theta^T x_i))^2 \\lVert x_i \\rVert^2 \\le \\frac 1 n \\lVert x_i \\rVert^2.$$\n",
    "\n",
    "Donc, $\\lVert Z_{n, i} \\rVert > \\varepsilon \\implies \\lVert x_i \\rVert > \\sqrt n \\varepsilon$.\n",
    "\n",
    "Alors\n",
    "\n",
    "$$\\begin{align*}\n",
    "0 \\le \\sum_{i=1}^n \\mathbb{E} \\left[ \\lVert Z_{n, i} \\rVert^2 \\mathbf{1}_{\\{\\lVert Z_{n, i} \\rVert > \\varepsilon\\}} \\right] &\\le \\sum_{i=1}^n \\frac 1 n \\lVert x_i \\rVert^2 \\mathbf{1}_{\\{\\lVert x_i \\rVert > \\sqrt n \\varepsilon\\}} \\\\\n",
    "&\\le \\sum_{i=1}^n \\frac { \\lVert x_i \\rVert^3 } { n \\lVert x_i \\rVert } \\mathbf{1}_{\\{\\lVert x_i \\rVert > \\sqrt n \\varepsilon\\}} \\\\\n",
    "&\\le \\frac 1 {\\sqrt n \\varepsilon} \\left( \\frac 1 n \\sum_{i=1}^n \\lVert x_i \\rVert^3 \\right) \\\\\n",
    "&\\le \\frac C { \\sqrt n \\varepsilon} \\xrightarrow[]{n \\to \\infty} 0.\n",
    "\\end{align*}$$\n",
    "\n",
    "Et donc, pour tout $\\varepsilon > 0$, on a $\\lim_{n \\to \\infty} \\sum_{i=1}^n \\mathbb{E} \\left[ \\lVert Z_{n, i} \\rVert^2 \\mathbf{1}_{\\{\\lVert Z_{n, i} \\rVert > \\varepsilon\\}} \\right] = 0$, et donc la première condition du théorème de Lindeberg-Feller est vérifiée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deuxième condition\n",
    "\n",
    "De plus, on a\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\sum_{i=1}^n \\mathrm{Var}(Z_{n, i}) &= \\sum_{i=1}^n \\mathbb{E} \\left[ Z_{n, i} Z_{n, i}^T \\right] \\\\\n",
    "&= \\frac 1 n \\sum_{i=1}^n  \\mathbb{E} \\left[ (Y_i - \\varphi(\\theta^T x_i))^2 x_i x_i^T \\right] \\\\\n",
    "&= \\frac 1 n \\sum_{i=1}^n  \\mathbb{E} \\left[ (Y_i - \\varphi(\\theta^T x_i))^2 \\right] x_i x_i^T \\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais $\\mathbb{E} \\left[ (Y_i - \\varphi(\\theta^T x_i))^2 \\right] = \\mathrm{Var}(Y_i) = \\varphi(\\theta^T x_i) (1 - \\varphi(\\theta^T x_i)) = h(\\theta^T x_i)$, donc\n",
    "\n",
    "$$\\sum_{i=1}^n \\mathrm{Var}(Z_{n, i}) = \\frac 1 n \\sum_{i=1}^n h(\\theta^T x_i) x_i x_i^T = \\frac 1 n F_n(\\theta) \\xrightarrow[]{n \\to \\infty} Q(\\theta),$$\n",
    "\n",
    "car d'après l'hypothèse H1, $\\frac 1 n F_n(\\theta) \\xrightarrow[]{n \\to \\infty} Q(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc, les conditions du théorème de Lindeberg-Feller sont vérifiées, et on a que la suite\n",
    "\n",
    "$$\\left\\{ \\sum_{i=1}^n Z_{n, i}, ~~ n \\in \\mathbb N \\right\\}$$\n",
    "\n",
    "converge en loi vers une variable aléatoire gaussienne centrée de matrice de covariance $Q(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Comme $\\nabla \\ell_n(\\hat \\theta_{n}) = 0$, on a\n",
    "\n",
    "$$\\frac 1 {\\sqrt n} \\nabla \\ell_n(\\theta) = \\left( \\frac 1 n F_n(\\theta) - R_n \\right) \\sqrt n (\\hat \\theta_{n} - \\theta).$$\n",
    "\n",
    "Donc\n",
    "\n",
    "$$\\frac 1 n F_n(\\theta) \\sqrt n (\\hat \\theta_{n} - \\theta) = \\frac 1 {\\sqrt n} \\nabla \\ell_n(\\theta) + R_n \\sqrt n (\\hat \\theta_{n} - \\theta).$$\n",
    "\n",
    "Or, $\\frac 1 {\\sqrt n} \\nabla \\ell_n(\\theta) \\xrightarrow[]{\\mathrm{loi}} \\mathcal N(0, Q(\\theta))$, et $R_n \\xrightarrow[]{\\mathbb{P}_{n, \\theta}\\text{-prob}} 0$. Alors d'après le théorème de Slutsky, on a\n",
    "\n",
    "$$\\frac 1 n F_n(\\theta) \\sqrt n (\\hat \\theta_{n} - \\theta) \\xrightarrow[]{\\mathrm{loi}} \\mathcal N(0, Q(\\theta)).$$\n",
    "\n",
    "D'autre part $\\frac 1 n F_n(\\theta) \\xrightarrow[]{n \\to \\infty} Q(\\theta)$, donc encore d'après le théorème de Slutsky, on a\n",
    "\n",
    "$$Q(\\theta) \\sqrt n (\\hat \\theta_{n} - \\theta) \\xrightarrow[]{\\mathrm{loi}} \\mathcal N(0, Q(\\theta)).$$\n",
    "\n",
    "On en déduit\n",
    "\n",
    "$$\\sqrt n (\\hat \\theta_{n} - \\theta) \\xrightarrow[]{\\mathrm{loi}} \\mathcal N(0, Q(\\theta)^{-1}),$$\n",
    "\n",
    "où $Q(\\theta)^{-1}$ est inversible, car $Q(\\theta)$ est définie positive d'après l'hypothèse H1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Comme la suite $(\\hat \\theta_{n})_{n \\ge 1}$ est consistante, on a\n",
    "\n",
    "$$\\frac{1} n F_n(\\hat \\theta_{n}) \\xrightarrow[]{n \\to \\infty} Q( \\theta),$$\n",
    "\n",
    "ce qui implique\n",
    "\n",
    "$$ \\left( \\frac{1} n F_n(\\hat \\theta_{n}) \\right)^{-1} \\xrightarrow[]{n \\to \\infty} Q( \\theta)^{-1}.$$\n",
    "\n",
    "On en déduit que $\\beta_{n,k} \\xrightarrow[]{n \\to \\infty} (Q( \\theta)^{-1})_{k,k}$.\n",
    "\n",
    "Et vu que $\\sqrt n \\left( \\hat \\theta_{n} - \\theta \\right) \\xrightarrow[]{\\mathrm{loi}} \\mathcal N(0, Q(\\theta)^{-1})$, on a\n",
    "\n",
    "$$\\sqrt n \\left( \\hat \\theta_{n,k} - \\theta_k \\right) \\xrightarrow[]{\\mathrm{loi}} \\mathcal N(0, (Q(\\theta)^{-1})_{k,k}),$$\n",
    "\n",
    "car il s'agit de la $k$-ème composante d'un vecteur asymptotiquement gaussien.\n",
    "\n",
    "Et donc d'après le théorème de Slutsky, on a\n",
    "\n",
    "$$ \\sqrt {  \\frac {n} {\\beta_{n,k}} } \\left( \\hat \\theta_{n,k} - \\theta_k \\right) \\xrightarrow[]{\\mathrm{loi}} \\mathcal N(0, 1).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14. Intervalles de confiance asymptotiques\n",
    "\n",
    "$$\\lim_{n \\to \\infty} \\mathbb{P}_{n, \\theta} \\left( \\sqrt {  \\frac {n} {\\beta_{n,k}} } \\left( \\hat \\theta_{n,k} - \\theta_k \\right) \\le u \\right) = \\mathbb{P} \\left( \\mathcal N(0, 1) \\le u \\right) = \\Phi(u).$$\n",
    "\n",
    "Ainsi, on trouve un intervalle de confiance asymptotique de niveau $1 - \\alpha$ pour $\\theta_k$:\n",
    "\n",
    "$$ I(\\alpha) = \\left[ \\hat \\theta_{n,k} - \\frac {u_{1 - \\alpha/2}} {\\sqrt {n/\\beta_{n,k}}}, \\hat \\theta_{n,k} + \\frac {u_{1 - \\alpha/2}} {\\sqrt {n/\\beta_{n,k}}} \\right],$$\n",
    "\n",
    "où $u_{1 - \\alpha/2}$ est le quantile d'ordre $1 - \\alpha/2$ de la loi normale centrée réduite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15. Test de niveau asymptotique $\\alpha$ pour $H_0: \\theta_k = 0$ contre $H_1: \\theta_k \\ne 0$\n",
    "\n",
    "On considère la statistique de test\n",
    "\n",
    "$$T(Z) = |\\hat \\theta_{n,k}|$$\n",
    "\n",
    "et la région de rejet\n",
    "\n",
    "$$\\mathcal R_\\alpha = \\left\\{ Z \\mid T(Z) > \\sqrt{ \\frac {\\beta_{n,k}} {n} } u_{1 - \\alpha/2} \\right\\}.$$\n",
    "\n",
    "Et donc d'après la question précédente, on a\n",
    "\n",
    "$$\\lim_{n \\to \\infty} \\mathbb{P}_{n, \\theta} (\\theta \\not\\in I(\\alpha)) = \\alpha.$$\n",
    "\n",
    "On en déduit que ce test répond à la question posée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16. Calcul de la $p$-valeur\n",
    "\n",
    "La $p$-valeur assymptotique $\\hat \\alpha(Z)$ vérifie\n",
    "\n",
    "$$ |\\hat \\theta_{n,k}| = \\sqrt{ \\frac {\\beta_{n,k}} {n} } u_{1 - \\hat \\alpha(Z)/2}.$$\n",
    "\n",
    "Donc\n",
    "\n",
    "$$\\hat \\alpha(Z) = 2 \\left( 1 - \\Phi \\left( \\frac {|\\hat \\theta_{n,k}|} {\\sqrt{ \\frac {\\beta_{n,k}} {n} }} \\right) \\right),$$\n",
    "\n",
    "où $\\Phi$ est la fonction de répartition de la loi normale centrée réduite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie Numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# charger les données \n",
    "loc= \"Titanic.csv\"\n",
    "data=pd.read_csv(loc, delimiter=\",\", skiprows=0)\n",
    "\n",
    "data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].mean())\n",
    "data.drop([\"Cabin\"], axis=1, inplace=True)\n",
    "dtype = {\"PassengerId\":int,\t\"Survived\": bool,\t\"Pclass\": int,\t\"Name\": str,\t\"Sex\": str,\t\"Age\": int,\t\"SibSp\": int,\t\"Parch\": int,\t\"Ticket\": str,\t\"Fare\": float,\t\"Embarked\": str}\n",
    "data = data.astype(dtype)\n",
    "\n",
    "preliminary_data = data.drop([\"PassengerId\", \"Ticket\",  \"Embarked\", \"Name\"], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of deaths was 549 out of 891 passengers.\n",
      "This represents  61.62% of the total.\n"
     ]
    }
   ],
   "source": [
    "num_passenger = preliminary_data[\"Survived\"].count()\n",
    "dead_passengers = preliminary_data[~preliminary_data[\"Survived\"]]\n",
    "num_dead = dead_passengers[\"Survived\"].count()\n",
    "\n",
    "print(f\"The total number of deaths was {num_dead} out of {num_passenger} passengers.\\nThis represents {100*num_dead/num_passenger: .2f}% of the total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of women who died: 81\n",
      "Percentage of women who died:  25.80%\n",
      "Number of men who died: 468\n",
      "Percentage of men who died:  81.11%\n",
      "The percentage of women between the people who passed away is:  14.75%\n",
      "The percentage of women between the people who survived is:  68.13%\n"
     ]
    }
   ],
   "source": [
    "num_dead_women = dead_passengers[dead_passengers[\"Sex\"] == \"female\"][\"Survived\"].count()\n",
    "num_women = preliminary_data[preliminary_data[\"Sex\"] == \"female\"][\"Survived\"].count()\n",
    "num_women_survived = num_women - num_dead_women\n",
    "num_dead_men = num_dead - num_dead_women\n",
    "num_men = num_passenger - num_women \n",
    "num_men_survived = num_men - num_dead_men\n",
    "\n",
    "print(f\"Number of women who died: {num_dead_women}\")\n",
    "print(f\"Percentage of women who died: {100*num_dead_women/num_women: .2f}%\")\n",
    "print(f\"Number of men who died: {num_dead_men}\")\n",
    "print(f\"Percentage of men who died: {100*num_dead_men/num_men: .2f}%\")\n",
    "print(f\"The percentage of women between the people who passed away is: {100*num_dead_women/num_dead: .2f}%\\nThe percentage of women between the people who survived is: {100*num_women_survived/(num_passenger-num_dead): .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’analyse de la proportion de passagers décédés par sexe montre que les hommes sont beaucoup plus nombreux que les femmes. En effet, les hommes ont proportionnellement 3,14 fois plus de chances de décéder que les femmes.\n",
    "\n",
    "Nous avons aussi que la proportion de femmes ayant survécu est nettement plus significative que celle des hommes. On peut donc en conclure que les femmes ont probablement été priorisées lors de l’évacuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For pclass = 1, we have:\n",
      "Number of women who died in p_class = 1: 3\n",
      "Percentage of women in p_class = 1 who died:  3.19%\n",
      "Number of men in p_class = 1 who died: 77\n",
      "Percentage of men in p_class = 1 who died:  63.11%\n",
      "The percentage of women between the people who passed away when p_class = 1 is:  3.75%\n",
      "The percentage of women between the people who survived when p_class = 1 is:  66.91%\n",
      "\n",
      "For pclass = 2, we have:\n",
      "Number of women who died in p_class = 2: 6\n",
      "Percentage of women in p_class = 2 who died:  7.89%\n",
      "Number of men in p_class = 2 who died: 91\n",
      "Percentage of men in p_class = 2 who died:  84.26%\n",
      "The percentage of women between the people who passed away when p_class = 2 is:  6.19%\n",
      "The percentage of women between the people who survived when p_class = 2 is:  80.46%\n",
      "\n",
      "For pclass = 3, we have:\n",
      "Number of women who died in p_class = 3: 72\n",
      "Percentage of women in p_class = 3 who died:  50.00%\n",
      "Number of men in p_class = 3 who died: 300\n",
      "Percentage of men in p_class = 3 who died:  86.46%\n",
      "The percentage of women between the people who passed away when p_class = 3 is:  19.35%\n",
      "The percentage of women between the people who survived when p_class = 3 is:  60.50%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passengers_per_class = preliminary_data[[\"Pclass\", \"Sex\", \"Survived\", \"Parch\"]].groupby([\"Sex\", \"Pclass\", \"Survived\"]).count()\n",
    "passengers_per_class.rename(columns={\"Parch\": \"Number\"}, inplace=True)\n",
    "passengers_per_class[\"Percentage\"] = passengers_per_class[\"Number\"] / passengers_per_class.groupby([\"Pclass\", \"Survived\"])[\"Number\"].transform(\"sum\") * 100\n",
    "passengers_per_class = passengers_per_class.reset_index()\n",
    "\n",
    "for pclass in range(1,4):\n",
    "    print(f\"For pclass = {pclass}, we have:\")\n",
    "    dead_women_percentage = passengers_per_class[(passengers_per_class[\"Pclass\"]== pclass)&(~passengers_per_class[\"Survived\"])&(passengers_per_class[\"Sex\"] == \"female\")][\"Percentage\"].sum()\n",
    "    alive_women_percentage = passengers_per_class[(passengers_per_class[\"Pclass\"]== pclass)&(passengers_per_class[\"Survived\"])&(passengers_per_class[\"Sex\"] == \"female\")][\"Percentage\"].sum()\n",
    "    num_dead_women = preliminary_data[(preliminary_data[\"Sex\"] == \"female\")&(preliminary_data[\"Pclass\"] == pclass)&(preliminary_data[\"Survived\"] == 0)][\"Survived\"].count()\n",
    "    num_dead_men = preliminary_data[(preliminary_data[\"Sex\"] == \"male\")&(preliminary_data[\"Pclass\"] == pclass)&(preliminary_data[\"Survived\"] == 0)][\"Survived\"].count()\n",
    "    num_women = preliminary_data[(preliminary_data[\"Sex\"] == \"female\")&(preliminary_data[\"Pclass\"] == pclass)][\"Survived\"].count()\n",
    "    num_men = preliminary_data[(preliminary_data[\"Sex\"] == \"male\")&(preliminary_data[\"Pclass\"] == pclass)][\"Survived\"].count()\n",
    "    print(f\"Number of women who died in p_class = {pclass}: {num_dead_women}\")\n",
    "    print(f\"Percentage of women in p_class = {pclass} who died: {100*num_dead_women/num_women: .2f}%\")\n",
    "    print(f\"Number of men in p_class = {pclass} who died: {num_dead_men}\")\n",
    "    print(f\"Percentage of men in p_class = {pclass} who died: {100*num_dead_men/num_men: .2f}%\")\n",
    "    print(f\"The percentage of women between the people who passed away when p_class = {pclass} is: {dead_women_percentage: .2f}%\\nThe percentage of women between the people who survived when p_class = {pclass} is: {alive_women_percentage: .2f}%\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout comme nous l’avons observé pour les sexes, il semble également que les décès soient liés à la classe du passager. Les passagers de première classe ont proportionnellement moins décédé que ceux de deuxième classe, qui eux-mêmes ont moins décédé que les passagers de troisième classe.\n",
    "\n",
    "En plus, on peut en conclure que :\n",
    "\n",
    "1.\tLa proportion d’hommes ayant survécu est significative uniquement en première classe. Ils faisaient donc partie des priorités lors des opérations de sauvetage.\n",
    "2.\tDans les classes moins aisées, le nombre de femmes décédées a été plus important, et la différence avec le nombre d’hommes décédés dans la même classe a été plus discrète.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Survived       Age     SibSp     Parch      Fare  Sex_male  \\\n",
      "Survived  1.000000 -0.067809 -0.035322  0.081629  0.257307 -0.543351   \n",
      "Age      -0.067809  1.000000 -0.232743 -0.176744  0.093856  0.082533   \n",
      "SibSp    -0.035322 -0.232743  1.000000  0.414838  0.159651 -0.114631   \n",
      "Parch     0.081629 -0.176744  0.414838  1.000000  0.216225 -0.245489   \n",
      "Fare      0.257307  0.093856  0.159651  0.216225  1.000000 -0.182333   \n",
      "Sex_male -0.543351  0.082533 -0.114631 -0.245489 -0.182333  1.000000   \n",
      "Pclass_2  0.093349  0.010199 -0.055932 -0.000734 -0.118557 -0.064746   \n",
      "Pclass_3 -0.322308 -0.285608  0.092548  0.015790 -0.413333  0.137143   \n",
      "\n",
      "          Pclass_2  Pclass_3  \n",
      "Survived  0.093349 -0.322308  \n",
      "Age       0.010199 -0.285608  \n",
      "SibSp    -0.055932  0.092548  \n",
      "Parch    -0.000734  0.015790  \n",
      "Fare     -0.118557 -0.413333  \n",
      "Sex_male -0.064746  0.137143  \n",
      "Pclass_2  1.000000 -0.565210  \n",
      "Pclass_3 -0.565210  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Convert categorical variables 'Sex' and 'Pclass' into dummy variables\n",
    "df_dummies = pd.get_dummies(preliminary_data, columns=[\"Sex\", \"Pclass\"], drop_first=True)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df_dummies.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En observant la matrice de corrélation des covariables, on constate que la colonne “Survived”, qui indique si le passager est décédé ou non, présente une forte corrélation avec les colonnes relatives au sexe (-0,54), au tarif (0,26) et à la classe (1ère : 0,23 ; 2ème : 0,09 ; 3ème : -0,32). On peut donc s’attendre à ce que l’estimation de la probabilité de survie dépende de certains de ces paramètres.\n",
    "\n",
    "En revanche, la corrélation entre le taux de survie et l’âge, le nombre de frères, sœurs et conjoints (SibSp), ainsi que le nombre de parents et enfants (Parch), est relativement faible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.442623\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  891\n",
      "Model:                          Logit   Df Residuals:                      883\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Fri, 01 Nov 2024   Pseudo R-squ.:                  0.3353\n",
      "Time:                        18:08:15   Log-Likelihood:                -394.38\n",
      "converged:                       True   LL-Null:                       -593.33\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.722e-82\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.8297      0.445      8.606      0.000       2.958       4.702\n",
      "Age           -0.0394      0.008     -5.027      0.000      -0.055      -0.024\n",
      "SibSp         -0.3493      0.109     -3.193      0.001      -0.564      -0.135\n",
      "Parch         -0.1118      0.118     -0.951      0.342      -0.342       0.119\n",
      "Fare           0.0030      0.002      1.227      0.220      -0.002       0.008\n",
      "Sex_male      -2.7605      0.199    -13.859      0.000      -3.151      -2.370\n",
      "Pclass_2      -1.0195      0.294     -3.471      0.001      -1.595      -0.444\n",
      "Pclass_3      -2.1514      0.290     -7.425      0.000      -2.719      -1.583\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "names = ['Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Pclass_2', 'Pclass_3']\n",
    "# Define the independent variables (X) and the dependent variable (y)\n",
    "x = df_dummies[names]\n",
    "y = df_dummies['Survived']\n",
    "y = y.astype({\"Survived\": int})\n",
    "\n",
    "dtype = {\"Pclass_2\": int,\t\"Pclass_3\": int,\t\"Sex_male\": int,\t\"Age\": int,\t\"SibSp\": int,\t\"Parch\": int,\t\"Fare\": float}\n",
    "x = x.astype(dtype=dtype)\n",
    "\n",
    "# Add an intercept (constant) term to X\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Fit the Logistic Regression model\n",
    "logit_model = sm.Logit(y, x)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 95% Confidence Intervals are:\n",
      "\n",
      "                 0         1\n",
      "const     2.957569  4.701930\n",
      "Age      -0.054729 -0.024026\n",
      "SibSp    -0.563775 -0.134914\n",
      "Parch    -0.342228  0.118689\n",
      "Fare     -0.001793  0.007797\n",
      "Sex_male -3.150958 -2.370129\n",
      "Pclass_2 -1.595095 -0.443809\n",
      "Pclass_3 -2.719350 -1.583498\n"
     ]
    }
   ],
   "source": [
    "# Calculate confidence intervals (95%)\n",
    "confidence_intervals = result.conf_int(alpha=0.05)\n",
    "print(\"\\nThe 95% Confidence Intervals are:\\n\")\n",
    "print(confidence_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On note d’abord que l’intervalle de confiance associé à Fare est très étroit et centré autour de zéro. Cela suggère que supprimer cette variable de notre analyse n’affecterait probablement pas beaucoup les résultats.\n",
    "\n",
    "Un phénomène similaire se produit avec Parch, bien que son intervalle de confiance soit légèrement plus large. Cependant, nous avions déjà observé que sa corrélation avec le taux de survie est presque nulle. Ainsi, il est probable que son influence sur les résultats ne soit pas significative non plus.\n",
    "\n",
    "De plus, on peut remarquer que la valeur de la constante est relativement élevée, ce qui justifie son inclusion dans le modèle. Le sexe, en revanche, a une influence manifeste sur le taux de survie, comme en témoigne le coefficient élevé.\n",
    "\n",
    "Enfin, les intervalles obtenus sont assez resserrés, ce qui est un comportement souhaité, car cela indique que la variance des données n’est pas trop élevée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value for Parch: 0.34182759732514556\n"
     ]
    }
   ],
   "source": [
    "# P-value for the hypothesis test H0: βParch = 0\n",
    "p_value_parch = result.pvalues['Parch']\n",
    "print(f\"P-value for Parch: {p_value_parch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en conclut que l’hypothèse $H_0$ est compatible avec les données, car la p-valeur est relativement élevée.\n",
    "\n",
    "Par conséquent, nous ne pouvons pas rejeter l’hypothèse nulle. Il est donc envisageable de retirer la variable Parch du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.443138\n",
      "         Iterations 6\n",
      "Model without Parch:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  891\n",
      "Model:                          Logit   Df Residuals:                      884\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Fri, 01 Nov 2024   Pseudo R-squ.:                  0.3345\n",
      "Time:                        18:08:15   Log-Likelihood:                -394.84\n",
      "converged:                       True   LL-Null:                       -593.33\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.245e-82\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.8058      0.442      8.601      0.000       2.939       4.673\n",
      "Age           -0.0391      0.008     -5.007      0.000      -0.054      -0.024\n",
      "SibSp         -0.3772      0.106     -3.557      0.000      -0.585      -0.169\n",
      "Fare           0.0025      0.002      1.073      0.283      -0.002       0.007\n",
      "Sex_male      -2.7247      0.195    -13.985      0.000      -3.107      -2.343\n",
      "Pclass_2      -1.0456      0.292     -3.585      0.000      -1.617      -0.474\n",
      "Pclass_3      -2.1832      0.287     -7.615      0.000      -2.745      -1.621\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fit a model without 'Parch' and calculate confidence intervals\n",
    "x_without_parch = x.drop(columns=['Parch'])\n",
    "logit_model_without_parch = sm.Logit(y, x_without_parch)\n",
    "result_without_parch = logit_model_without_parch.fit()\n",
    "\n",
    "print(\"Model without Parch:\")\n",
    "print(result_without_parch.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 95% Confidence Intervals excluding Parch are:\n",
      "\n",
      "                 0         1\n",
      "const     2.938543  4.673090\n",
      "Age      -0.054434 -0.023808\n",
      "SibSp    -0.585049 -0.169391\n",
      "Fare     -0.002061  0.007049\n",
      "Sex_male -3.106537 -2.342807\n",
      "Pclass_2 -1.617128 -0.474003\n",
      "Pclass_3 -2.745112 -1.621275\n"
     ]
    }
   ],
   "source": [
    "# Calculate confidence intervals (95%)\n",
    "confidence_intervals_q7 = result_without_parch.conf_int(alpha=0.05)\n",
    "print(\"\\nThe 95% Confidence Intervals excluding Parch are:\\n\")\n",
    "print(confidence_intervals_q7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous avons constaté que la longueur des intervalles a légèrement diminué, sans qu’il y ait de différence significative après la suppression du paramètre du modèle. Cela confirme la conclusion tirée de la p-valeur, à savoir que retirer ce paramètre était une décision justifiée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value for Fare: 0.28325267177106317\n"
     ]
    }
   ],
   "source": [
    "# P-value for the hypothesis test H0: βFare = 0\n",
    "p_value_fare = result_without_parch.pvalues['Fare']\n",
    "print(f\"P-value for Fare: {p_value_fare}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en conclut que l’hypothèse $H_0$ est compatible avec les données, car la p-valeur est relativement élevée.\n",
    "\n",
    "Par conséquent, nous ne pouvons pas rejeter l’hypothèse nulle. Il est donc envisageable de retirer la variable Fare du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.443835\n",
      "         Iterations 6\n",
      "Model without Parch and Fare:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  891\n",
      "Model:                          Logit   Df Residuals:                      885\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Fri, 01 Nov 2024   Pseudo R-squ.:                  0.3335\n",
      "Time:                        18:08:15   Log-Likelihood:                -395.46\n",
      "converged:                       True   LL-Null:                       -593.33\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.455e-83\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.0183      0.399     10.083      0.000       3.237       4.799\n",
      "Age           -0.0398      0.008     -5.104      0.000      -0.055      -0.024\n",
      "SibSp         -0.3569      0.104     -3.433      0.001      -0.561      -0.153\n",
      "Sex_male      -2.7404      0.194    -14.114      0.000      -3.121      -2.360\n",
      "Pclass_2      -1.1869      0.262     -4.535      0.000      -1.700      -0.674\n",
      "Pclass_3      -2.3502      0.243     -9.669      0.000      -2.827      -1.874\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fit a model without 'Parch' and 'Fare'\n",
    "x_without_parch_fare = x.drop(columns=['Parch', 'Fare'])\n",
    "logit_model_without_parch_fare = sm.Logit(y, x_without_parch_fare)\n",
    "result_without_parch_fare = logit_model_without_parch_fare.fit()\n",
    "\n",
    "print(\"Model without Parch and Fare:\")\n",
    "print(result_without_parch_fare.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 95% Confidence Intervals excluding Parch and Fare are:\n",
      "\n",
      "                 0         1\n",
      "const     3.237190  4.799357\n",
      "Age      -0.055016 -0.024488\n",
      "SibSp    -0.560743 -0.153147\n",
      "Sex_male -3.120983 -2.359897\n",
      "Pclass_2 -1.699824 -0.673973\n",
      "Pclass_3 -2.826593 -1.873810\n"
     ]
    }
   ],
   "source": [
    "# Calculate confidence intervals (95%)\n",
    "confidence_intervals_q9 = result_without_parch_fare.conf_int(alpha=0.05)\n",
    "print(\"\\nThe 95% Confidence Intervals excluding Parch and Fare are:\\n\")\n",
    "print(confidence_intervals_q9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous avons constaté que la longueur des intervalles a légèrement diminué, sans qu’il y ait de différence significative après la suppression du paramètre du modèle. Cela confirme la conclusion tirée de la p-valeur, à savoir que retirer ce paramètre était une décision justifiée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord on analyse la prediction donné par le modèle qui prend en compte les colomnes Fare et Parch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of survival for a 22-year-old male in 1st class:  58.10%\n",
      "Probability of survival for a 22-year-old female in 1st class:  96.13%\n"
     ]
    }
   ],
   "source": [
    "# Predict survival probabilities for specific cases\n",
    "\n",
    "# Case 1: Male, 22 years old, no family (SibSp=0, Parch=0), 1st class\n",
    "\n",
    "median_fare_1st_class_male = df_dummies[(df_dummies['Pclass_2'] == 0)&(df_dummies['Pclass_3'] == 0)&(df_dummies[\"Sex_male\"]==1)]['Fare'].median()\n",
    "male_22 = [1, 22, 0, 0, median_fare_1st_class_male, 1, 0, 0]\n",
    "prob_male_22 = result.predict([male_22])[0]\n",
    "\n",
    "# Case 2: Female, 22 years old, no family, 1st class\n",
    "median_fare_1st_class_female = df_dummies[(df_dummies['Pclass_2'] == 0)&(df_dummies['Pclass_3'] == 0)&(df_dummies[\"Sex_male\"]==0)]['Fare'].median()\n",
    "female_22 = [1, 22, 0, 0, median_fare_1st_class_female, 0, 0, 0]\n",
    "prob_female_22 = result.predict([female_22])[0]\n",
    "\n",
    "print(f\"Probability of survival for a 22-year-old male in 1st class: {prob_male_22*100: .2f}%\")\n",
    "print(f\"Probability of survival for a 22-year-old female in 1st class: {prob_female_22*100: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous effectuons le même calcul, mais avec le modèle sans ces colonnes. Le résultat est présenté ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of survival for a 22-year-old male in 1st class:  59.95%\n",
      "Probability of survival for a 22-year-old female in 1st class:  95.87%\n"
     ]
    }
   ],
   "source": [
    "# Predict survival probabilities for specific cases\n",
    "\n",
    "# Case 1: Male, 22 years old, no family (SibSp=0, Parch=0), 1st class\n",
    "male_22 = [1, 22, 0, 1, 0, 0]\n",
    "prob_male_22 = result_without_parch_fare.predict([male_22])[0]\n",
    "\n",
    "# Case 2: Female, 22 years old, no family, 1st class\n",
    "female_22 = [1, 22, 0, 0,  0, 0]\n",
    "prob_female_22 = result_without_parch_fare.predict([female_22])[0]\n",
    "\n",
    "print(f\"Probability of survival for a 22-year-old male in 1st class: {prob_male_22*100: .2f}%\")\n",
    "print(f\"Probability of survival for a 22-year-old female in 1st class: {prob_female_22*100: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, étant donné que les deux résultats sont très similaires, nous concluons que la suppression de ces paramètres dans notre analyse était justifiée.\n",
    "\n",
    "De plus, il est également notable que la probabilité de survie est considérablement plus élevée pour la femme, ce qui était attendu compte tenu des résultats des premières questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
